Merge pull request #6878 from timgates42/bugfix/typo_overridden
Fix simple typo: overrided -> overridden
Updated Intel's branch description
Updated Intel's branch description
Merge pull request #6499 from xerus/python_gpu
Merge pull request #6461 from open-cv/patch_1
Merge branch 'master' into patch_1
Merge pull request #6455 from lengly/patch-1
Merge pull request #6346 from jerryz123/HDF5_config
Merge pull request #6320 from Noiredd/clip
Clip layer documentation
test case fix for Clip layer gradient
Add clip layer
Merge pull request #6282 from Noiredd/pooling-mode
python: Set gpu device id before setting gpu mode
fix typos and some minor fixes.
Update inner_product_layer.cpp
Merge pull request #6238 from mitar/manual-sgd
[pycaffe] test solver update
[pycaffe] expose mutable solver parameter, base lr, and effective lr
increment iteration during update, not step
[pycaffe] expose solver update to do manual solving
Merge pull request #6390 from open-cv/fix-6389
Merge pull request #6388 from open-cv/fix-6387
fix issue #6389
fix issue #6387.
Merge pull request #6219 from uhfband/fix-caffe_pb2-module
Cherry-picked USE_HDF5 from Android branch
Merge pull request #6342 from Noiredd/gauss-fill-test-fix
tweaked Gaussian filler tests for less false fails
Revised guidelines for GitHub issues (#6327)
Fix cmake < v3.7 compatibility in Cuda.cmake (#6338)
Merge pull request #6336 from Coderx7/master
Minor correction concerning compilation compatibility with CUDA 9.0
Merge pull request #6237 from jasjuang/master
Merge pull request #6277 from twmht/dev_issue_6268
check embed index in debug mode
Added Swish layer (#6002)
Merge pull request #6286 from Noiredd/bilinear-filler-fix
bilinear filter test refactor
Merge pull request #6278 from Noiredd/filler-fix
Filler testing overhaul
PoolingLayer customizable output shape rounding mode
Add lr_mult label to the network graph in draw_net.py (#6273)
1D blob handling in MSRA/Xavier fillers
Merge pull request #6249 from Noiredd/legacy-tools
Remove legacy tools
Merge pull request #6104 from YaYaB/master_bvlc
Merge pull request #5149 from yanchen036/master
Merge pull request #6176 from qu1j0t3/simplify-pip-cmd
Merge pull request #6240 from knsong/master
Fix compatibility for ND convolution
bug fix: ext should not include the '.'
fix cuda 9.1 compilation
Merge pull request #6123 from IlyaOvodov/master
Automatic replacement of snapshot_prefix parameter if it is empty or points to a directory. See issue #6110 proposed improvement No.2
Weight parameter in solver is used in caffe.exe
Fix incorrect namespace for pycaffe submodule caffe_pb2 generated by protobuf
Merge pull request #5598 from ZoroDerVonCodier/patch-1
Merge pull request #6210 from mzsanford/classfier_deprecation_warning
Update Classifier and Detector to avoid deprecation warning
Merge pull request #5545 from brunobowden/shape_mismatch_checks
corrected description of set_transpose in io.py
Merge pull request #5865 from cheshirekow/fix/caffe_rpath
Merge pull request #6202 from shelhamer/fix-scratch-bottom-diff
explain use of scratch diffs in comments
clear scratch use of accuracy bottom diff
clear scratch use of loss bottom diffs
Merge pull request #5924 from bowang/cudnn_deconv
Merge pull request #6201 from shelhamer/official-aws-ami
docs: switch to official AWS AMI
Simplify pip invocation.
Merge pull request #6048 from sclarkson/master
Merge pull request #6121 from xerus/typo
Cuda.cmake: Fix a typo in a comment
Add check values of gamma and stepsize to avoid unexplained core dump
Merge pull request #6084 from Noiredd/accuracy-count-fix
Added count==0 safeguard to CPU accuracy calculation
Merge pull request #6079 from Noiredd/cuda9-makefile
Makefile example comments for CUDA 9.0 compatibility
Fix Makefile parallel builds missing protobuf header
Merge pull request #5972 from icyblade/icyblade-patch-1
Merge pull request #5719 from leemgs/upstream-issue5718
Fix: mean shape in compatible with input shape
Merge pull request #5813 from jqueguiner/patch-1
Merge pull request #5704 from ArneSuppe/dupDistDirFix
Merge pull request #5969 from developius/fix-default-mode-warning
Merge pull request #5866 from cijianzy/update_link_to_google_style_guide
Merge pull request #5973 from Noiredd/pytest
infogain loss: fix bottom blobs description
Merge pull request #5925 from BVLC/williford-install-ubuntu-16.04-patch-1
Add absolute tolerance to test_net.py to prevent random Travis fails
add supports for cuDNN v7
upgrading Accuracy layer: (1) efficient CPU implementation O(L) for top_k, no need for fancy priority_queue etc. (2) GPU implementation
Fix default mode warning in io.resize_image
[docs] fix link to `AbsVal` layer
Merge pull request #5713 from Noiredd/filler
Fixed bilinear filler, added tests
Merge pull request #5904 from longjon/gpu-ptr
Packages needed by Ubuntu 16.04 also
Fix format
Implement CuDNN-based deconvolution layer and test
Expose GPU pointers to Python
Merge pull request #5900 from wasnot/fix/py3-division-compat
modified division operator for compatibility of python 3
Update link to google style guide.
Fix caffe rpath
Update README.md
Merge pull request #5824 from ek9852/master
Fix hardcode xcode path
Merge pull request #5753 from CDLuminate/docs-update-deb-ub
Merge pull request #5760 from Lydorn/patch-1
Merge pull request #5770 from skylarjhdownes/master
[DOC][FIX] fix web demo install instruction link
update deprecated pandas call
update sklearn calls to use latest API
Update lrn.md
docs: add Ubuntu package tracker link in Ubuntu guide
docs: update apt installation guide for Debian and Ubuntu
Fixed bug where make distribute duplicates python files in distribute/python
Update README.md
Merge pull request #5687 from BVLC/readme_list_branches
List branches in readme
Merge pull request #5624 from CDLuminate/cmake-rename-static-proto-library
Merge pull request #5625 from CDLuminate/docs-update
docs/debian guide: update compiler combination table
cmake: rename libproto.a -> libcaffeproto.a
Merge pull request #5617 from lukeyeager/boost-1.54
Downgrade boost requirement from 1.55 to 1.54
Update euclidean_loss_layer.hpp
Merge pull request #5548 from erictzeng/crop
Merge pull request #5588 from ShaggO/matlab-fix-delete
Handling destruction of empty Net objects
Fix crop layer lint errors
Rewrite crop cuda kernel
Shape mismatch CHECK logging improvements
Merge pull request #5530 from willyd/nccl-py3
Merge pull request #5539 from shelhamer/caffe-1.0
Merge pull request #5536 from cypof/docker_cudnn6
Merge pull request #5537 from shelhamer/docs-grooming
Merge pull request #5531 from shelhamer/py-test-layer-top-names
Merge pull request #5529 from shelhamer/deprecate-window
Caffe 1.0
link to new full-day crash course
track publications by google scholar and not the wiki
retire caffe-dev and caffe-coldpress
add missing names to BAIR roster
model zoo: point out wiki link immediately, explain manual editing
favor notebook examples as more clear and popular
drop performance + hardware page and switch to sheet
BVLC -> BAIR
Docker update to cuDNN 6
fix lint errors that snuck in by #4566
Merge pull request #2612 from ih4cku/master
Merge pull request #3410 from ghost/patch-2
Merge pull request #3411 from ghost/patch-3
Merge pull request #3153 from jeffdonahue/netspec-type-check
Merge pull request #3913 from antran89/master
Merge pull request #3855 from shaibagon/upgrade_infogain
[docs] added apt command to install OpenBLAS (#4718)
Merge pull request #5514 from cypof/fix_parse_log
Merge pull request #4566 from CDLuminate/fix-more-float-comparison-issue
Test for python forward and backward with start and end layer.
Merge pull request #3825 from jasjuang/master
Merge pull request #5519 from Noiredd/master
Explicit std::string to bp::object conversion
Merge pull request #4237 from CDLuminate/cmake-using-gnuinstalldirs
Merge pull request #4576 from CDLuminate/add-bash-completion
[examples] switch cifar-10 back to proto instead of h5 serialization
Merge pull request #5526 from willyd/boost-1_55
Updated Travis boost dependencies
Merge pull request #5527 from willyd/nccl-py3
deprecate WindowData layer type
Merge pull request #5521 from kkhoot/fix_lstm_unit_check
fix: add non-MKL sqrt (should have been included in ab33988)
Merge pull request #4182 from ajschumacher/handle_dtypes
Merge pull request #5136 from pfollmann/fix_batchnorm_layer
CPU BatchNormLayer: replace powx with sqr and sqrt
Add CPU sqrt functions
GPU BatchNormLayer: replace powx with mul and sqrt
Add GPU sqrt functions
Added support for python 3 and NCCL
Bump boost version to 1.55 in CMake build
Merge pull request #5337 from zhuyuanhao/master
Merge pull request #5437 from BlGene/test-path-fix
remove redundant check in LSTMUnitLayer
Merge pull request #5506 from willyd/pycaffe-fix
Merge pull request #5515 from cypof/py_glog_env
Merge pull request #5420 from willyd/py3-lint
fixes pycaffe forward() and backward() behavior for nets whose layer names do not match respective tops
Allow using env vars for glog init from python
Fix log parsing #5422
Merge pull request #5474 from willcrichton/master
Merge pull request #5408 from cypof/multi_infer
Merge pull request #5455 from cypof/remove_shared_parallel
Merge pull request #5503 from brunobowden/shape_check_eq
Log shape dimensions for eltwise layer shape mismatch
Removed repeated import Layer, get_solver
Merge pull request #5380 from gineshidalgo99/pull-request-supressed-some-warnings
Merge pull request #5467 from yuduowu/master
Merge pull request #5491 from caffe-help/sigmoid-doc-1
Merge pull request #5487 from nitheeshas/fix-draw-net
Add example and small blurb about sigmoid layer.
Add main() for draw_net unittest, fix import errors
Minor fix for net drawing script
Merge pull request #5477 from lukeyeager/bvlc/test-draw-net
Merge pull request #5478 from flx42/cudnn6-support
Add test for caffe.draw.draw_net()
Add support for cuDNN v6
Revert "Fix Python net drawing script"
Fixed memory leaks in cudnn conv and relu
Fix typo in test_caffe_main.cpp: defice -> device
Remove missed legacy parallel code
Expose share_weights to python to allow running test nets
Merge pull request #5434 from williford/batchnorm_doc2
[caffe][build] added ABS_TEST_DATA_DIR var.
[caffe][build] added Atlas lapack Library name atllapack
Clarify batch norm parameter documentation.
Merge pull request #5372 from BlGene/hdf5-load-fix
sane h5df file type check for weights
Added python 3 compatibility to cpp_lint.py
Init test net on all GPUs, allows parallel inference
Merge pull request #5393 from jfolz/master
Solver_add_nccl accepts any kind of Solver
Removed some 'warning: extra ‘;’ [-Wpedantic]'
Merge pull request #4630 from BlGene/load_hdf5_fix
Remove not used variable in base_conv_layer.cpp
fix broken link to hinge loss
Merge pull request #5296 from shelhamer/rc5
version bump: rc5
Merge pull request #4609 from intelfx/BVLC-work-buildsystem
Merge pull request #4737 from rokm/matcaffe-individual-destruct
Merge pull request #4721 from kashefy/fix_matlab_demo_typos
Merge pull request #5010 from ngaloppo/fix_drawnet
Merge pull request #5074 from garion9013/master
Merge pull request #3893 from rscohn2/patch-1
Merge pull request #4347 from nitnelave/python/layer_dict
Merge pull request #5236 from solrex/veclib-fix
Merge pull request #5210 from ftokarev/patches
Merge pull request #5272 from crowsonkb/master
Add Pascal CUDA architectures to Makefile.config.example
make: bump version to rc4
Document switch to explicit flags for docker: cpu / gpu.
Merge pull request #5242 from CDLuminate/doc-update-debian-guide
docs: update install_apt_debian guide
Remove sdk version from veclib searching path.
Merge pull request #5227 from williford/caffe-git-pr2
Fix broken links in layer documentation, minor fixes.
Merge pull request #5220 from kts/bugfix
parse_log.py was not using --verbose argument
Merge pull request #5215 from cypof/fix_restore
Restore can be invoked on rank > 0
Merge pull request #5207 from CDLuminate/cmake-bump-soversion-to-rc4
Update a comment in caffe.proto
cmake: bump soversion to rc4
Merge pull request #5153 from cypof/docker
Docker refresh: simplified & update to 16.04, cuda8, cudnn5, nccl
Merge pull request #5198 from longjon/config-backslash
Merge pull request #5184 from shaibagon/fix_batch_norm_param_upgrade
Merge pull request #3365 from BonsaiAI/wrap-declarations-in-switch
copyright spans 2014-2017
ignore generated includes for docs
[build] remove trailing backslash on comment
Merge pull request #4842 from willyd/pytest-fix
remove redundant operations in Crop layer (#5138)
Merge pull request #5025 from hmybmny/master
Merge pull request #5098 from yaronli/master
Merge pull request #5121 from yrevar/patch-2
Merge pull request #5142 from lvchaxj/master
Merge pull request #5176 from stoneyang/minor
Fix various documentation typos (#4172)
Merge pull request #5148 from caffe-help/caffe-docs-PR1
Merge pull request #5181 from willyd/download-model-py3
Merge pull request #4563 from cypof/nccl
fixing upgrade_proto for BatchNorm layer: be more conservative leave "name" in param, only set lr_mult and decay_mult to zero
Merge pull request #5075 from tsocha/master
Merge pull request #5111 from CDLuminate/add-debian-install-guide
Python 2/3 compatible download_model_binary.py
minor typo
Merge pull request #4338 from raffienficiaud/master
Using default from proto for prefetch
Python layers should build on multiprocess & solver_cnt; enable with bindings
Python Multi-GPU
Switched multi-GPU to NCCL
Logging from python, e.g. for lower log level on multi-GPU workers
docs: add some tables to debian install guide and misc update
docs: update debian installation guide. Thanks to @lukeyeager for comments.
Add Debian codenames and make link.
Overhaul layer catalogue documentation.
Fix parse_log.py and parse_log.sh for negative time duration if datetime in log across year boundary
Merge pull request #5139 from ftokarev/patches
Typos in test_inner_product_layer.cpp
Join path using "os.path.join" instead of "+"
Merge pull request #5112 from yrevar/patch-1
Fixed a typo
Use mkl_malloc when use mkl
docs: add debian installation guide
check leveldb iterator status for snappy format.
fix wrongly used marker hash
Merge pull request #5057 from Queuecumber/cuda-pascal-cmake
Add Pascal to all cuda architectures
Merge pull request #5038 from CDLuminate/fix-spelling
Add the missing period
Make lint happy (> 80 characters)
Merge pull request #5035 from CDLuminate/fix-spelling
fix many typos by using codespell
Revert "solver: check and set type to reconcile class and proto"
fix error link
Merge pull request #5009 from shelhamer/solver-type-check
Merge pull request #4998 from chenzeyuczy/master
Fix Python net drawing script
Checks inside Xcode for latest OSX SDK (#4840)
solver: check and set type to reconcile class and proto
Merge pull request #4703 from cypof/avoid_missing_returns
Merge pull request #4979 from davidbrai/allow-parse_log-to-skip-lines
Add missing spaces besides equal signs in batch_norm_layer.cpp
Merge pull request #4986 from shelhamer/sigce-ignore
sigmoid cross-entropy loss: normalize loss by different schemes
Merge pull request #4993 from shelhamer/bitfusion-ami
docs: include AWS AMI pointer
docs: Guillaume Dumont is the Windows maintainer
sigmoid cross-entropy loss: ignore selected targets by `ignore_label`
support solver resumes in parse_log.py
Merge pull request #4971 from williford/docs-installation-add-quotes
Put quotes around titles in YAML front matter.
Merge pull request #4914 from williford/issue_template
Add Github issue template to curb misuse.
Merge pull request #4941 from karas84/caffe-pr
Merge pull request #4937 from nihui/patch-1
corrected typo in accuracy_layer.hpp: MaxTopBlos -> MaxTopBlobs
add the missing star in comment
Merge pull request #4908 from shelhamer/sigce-gpu
sigmoid cross-entropy loss: add GPU forward for full GPU mode
Fix: made load_hd5 check blob dims by default.
pytest fix: Files created with NamedTemporary files cannot be opened on Windows
Merge pull request #4813 from Shamanoid/patch-1
Merge pull request #4812 from wk910930/fix-typo
Fix: docs/yum_install.md glog broken link
fix typo in pascal_multilabel_datalayers.py
Merge pull request #4793 from cypof/cudnn_path
NV changed path to cudnn
Merge pull request #4785 from bwilbertz/slightly_relax_batch_norm_check
slightly relax batch norm check
Merge pull request #4779 from shelhamer/ignore-visualstudio
Ignore Visual Studio Code files.
Merge pull request #4769 from lukeyeager/bvlc/travis-protobuf3-url
[TravisCI] google/protobuf renamed the 3.0 branch
Merge pull request #4600 from bwilbertz/fix_scale_layer
matcaffe: allow destruction of individual networks and solvers
Merge pull request #4704 from shelhamer/groom-batch-norm
Merge pull request #4728 from mlloreda/patch-1
Fixed typos in examples/cpp_classification/readme
fix comments in matlab classification demo
batch norm: auto-upgrade old layer definitions w/ param messages
batch norm: hide statistics from solver, simplifying layer definition
[docs] identify batch norm layer blobs
Merge pull request #4705 from shelhamer/ubuntu-cuda-version
[docs] note CUDA 8 requirement for Ubuntu 16.04
[docs] clarify handling of bias and scaling by BiasLayer, ScaleLayer
Merge pull request #4702 from cypof/timer_sync_on_read
Avoids missing return values during build.
Benchmarking should not impact perf until timer is read
fix layerSetUp of scale_layer to not add bias blob when already present
cmake/Templates: remove duplicated #cmakedefines from caffe_config.h.in
cmake: add option to link with OpenMP
net.cpp: do not include test/test_caffe_main.hpp
cmake: refactor deps detection, specify all dependencies in the exported caffe target
cmake/Templates: properly spell OpenCV CMake config file name
cmake: fix usage of INCLUDE_DIR/INCLUDE_DIRS in Dependencies.cmake
Merge pull request #4647 from ClimbsRocks/patch-3
Merge pull request #4646 from ClimbsRocks/patch-2
Merge pull request #4645 from ClimbsRocks/patch-1
Merge pull request #4655 from lukeyeager/bvlc/protobuf3-build-fix
[TravisCI] - build protobuf3 GA
changes "c++" to "C++" for consistency
fixes typo- duplicate "a a"
updates tense in docs
Merge pull request #4589 from sungjunhong/master
Merge pull request #4605 from shelhamer/osx-cudnn-dylib
make cmake find cuDNN on Mac OS
Merge pull request #4604 from shelhamer/fix-elcap-blas
[build] set default BLAS include for OS X 10.11
Merge pull request #3272 from ixartz/master
Merge pull request #4247 from jklontz/master
Merge pull request #4596 from keskarnitish/master
Fixing Typo In Sigmoid CIFAR-10 Examples
Correct a mistake on math notation
small improments in compute_image_mean
Merge pull request #4379 from alicanb/master
Import bash completion script for caffe from Debian Package.
Fix more float comparison precision issue
Merge pull request #4559 from fyu/loss_reshape
num in blob is deprecated
Merge pull request #4516 from intelfx/BVLC-work
Merge pull request #4523 from delftrobotics/cmake-atlas
Fix search for Atlas on arch.
CMake: link with ${HDF5_HL_LIBRARIES}
add in sudo make uninstall for cmake
Merge pull request #4474 from lukeyeager/bvlc/travis-cache
Stop setting cache timeout in TravisCI
Merge pull request #4459 from lukeyeager/bvlc/example-scripts
Merge pull request #4455 from ShaggO/spaceSupportILSVRC12MNIST
Add "set -e" and $@ to example scripts
Support spaces in path when downloading ILSVRC12 and MNIST
Merge pull request #4343 from nitnelave/python/top_names
Merge pull request #4451 from ShaggO/cifar10space
add test for top/bottom names
improve top_names and bottom_names in pycaffe
Support for spaces in directories when downloading cifar10
Merge pull request #4351 from nitnelave/python/set_random_seed
Merge pull request #4448 from lalelale/patch-2
Update parse_log.py
add set_random_seed to the python interface
Merge pull request #4359 from ibmsoe/fix-EmbedLayerTest
Fix for a random failure in this test due to floating point comparison. So, instead of exact match, used EXPECT_FLOAT_EQ that tolerates some precision while comparing two floats
Merge pull request #4348 from nitnelave/python/clear_params
Merge pull request #2984 from marco-c/dont_squeeze
Merge pull request #4433 from lukeyeager/bvlc/cmake-install-python
Merge pull request #4408 from cdoersch/draw_net_phase
Merge pull request #3863 from lukeyeager/bvlc/expose-all-netstate-options
Fix Python installation with CMake install target
Add phase support for draw net
corrected rmsprop documentation
add default value for rms_decay
add tests for pycaffe's layer_dict
add unit test for clear_param_diffs
add clear_param_diffs to the python net interface
add layer_dict to the python interface
Fix glog upstream autoconf
Merge pull request #3020 from philkr/python_solver_callback
Exposing solver callbacks to python
Add level and stages to pycaffe
Add phase, level and stages to tools/caffe
Add level and stages to Net constructor
Merge pull request #4227 from philkr/save_hdf5
Exposing load_hdf5 and save_hdf5 to python
Merge pull request #4259 from chuckcho/fixing-typo
Fixing a typo
Merge pull request #4254 from lukeyeager/bvlc/travis-caching
Merge pull request #3948 from jeffdonahue/recurrent-layer
Add LSTMLayer and LSTMUnitLayer, with tests
Add RNNLayer, with tests
Add RecurrentLayer: an abstract superclass for other recurrent layer types
Cache protobuf3 build in TravisCI
Fix vecLib search order for clients with both the old vecLib framework and the new Accelerate framework
Merge pull request #4236 from CDLuminate/fix-spelling-error
Merge pull request #4218 from malreddysid/master
fix install path with GNUInstallDir support
fix install path with GNUInstallDir support
fix install path with GNUInstallDir support
using GNUInstallDirs in root cmake file
fix spelling error in memory_data_layer.cpp
Check for non-empty ImageData filelist.
Merge pull request #4214 from lukeyeager/bvlc/remove-comment-in-tests
Remove misleading comment from a test file
Merge pull request #4207 from lukeyeager/bvlc/travis-overhaul
Overhaul TravisCI
convert non-uint8 dtypes to float; refs #2391
Merge pull request #4059 from crazytan/master
handle image names with spaces
Merge pull request #4070 from crazytan/ipython
Merge pull request #4146 from yalesong/fix-makefile-osx-yosemite
Merge pull request #4148 from bobpoekert/window_data_nonzero_check
Merge pull request #4159 from flx42/cudnn_v5_support
Update supported cuDNN version in the documentation
Update Dockerfile to cuDNN v5
Add cuDNN v5 support, drop cuDNN v3 support
add check for background and foreground window size > 0 in WindowData layer
Merge pull request #4144 from millskyle/python_io_typo
Fix Makefile CUDA_VERSION extraction on OSX Yosemite
fixed typo in io.py
Merge pull request #4128 from gdh1995/master
a comment misses a space char
Merge pull request #4121 from rayglover-ibm/cmake
[build] (CMake) customisable Caffe version/soversion
Merge pull request #4117 from lukeyeager/bvlc/fix-lmdb-pr
Catch MDB_MAP_FULL errors from mdb_txn_commit
Merge pull request #2079 from longjon/parameter-layer
Merge pull request #4101 from erictzeng/reshape_zero
Allow reshaping blobs to size 0.
fix problems in net_surgery.ipynb
add parameter layer for learning any bottom
Merge pull request #4094 from shelhamer/make-clean-clears-distribute
[build] note that `make clean` clears build and distribute dirs
Merge pull request #4048 from achalddave/python_plot_exit_properly
Merge pull request #3995 from ZhouYzzz/python-phase
Merge pull request #4082 from flx42/pin_base_docker_image
Fix typo (indecies->indices)
Reformat to fit in 79 columns
Remove trailing spaces
Exit on error and report argument error details.
Add test for attribute "phase" in python layer
Merge pull request #3977 from tpwrules/master
Merge pull request #4040 from ebadawy/master
Merge pull request #4056 from wk910930/fix-ReshapeParameter-example
Merge pull request #4065 from drewabbot/master
Merge pull request #4075 from szha/osx_makefile_fix
Pin the base image version for the GPU Dockerfile
Merge pull request #4071 from mnogu/optional-name
fix grep in CUDA version detection to accomodate OSX's grep (and other grep that doesn't support \d extension)
draw_net: accept prototxt without name
Merge pull request #4069 from seanbell/pycaffe-boost-warnings-fix
Suppress boost registration warnings in pycaffe (Based on #3960)
avoid non-integer array indices
Merge pull request #4051 from samster25/master
Fix an error in the example of ReshapeParameter.
fixed typo in download script command cpp_classification
Merge pull request #4033 from HeGaoYuan/master
Merge pull request #3731 from lukeyeager/lmdb-map-full
Read the data as a binary
Fixed #4029: test the network every 500 iterations, not 1000 iterations
Update MNIST example to use new DB classes
Print to stderr for example LMDB code
Don't set map_size=1TB in util/db_lmdb
Merge pull request #4024 from achalddave/finetune-flickr-style-tutorial
Merge pull request #3749 from lukeyeager/bvlc/array_to_datum-default-label
Explicitly point out -weights flag in tutorial
Merge pull request #4007 from lukeyeager/bvlc/docs-typo
Typo in docs/installation.md
Allow the python layer have attribute "phase"
Merge pull request #3993 from shelhamer/fix-crop
CropLayer: groom comments
[fix] CropLayer: check dimension bounds only for cropped dimensions
[test] CropLayer: test dimensions check to reveal bounds checking bug
Merge pull request #3988 from shelhamer/install-docs
[docs] install: include more lab tested hardware
[docs] install: be more firm about compute capability >= 3.0
[docs] install: include latest versions and platforms, highlight guides
[docs] install: CUDA 7+ and cuDNN v4 compatible
Merge pull request #3982 from mnogu/fix-typo-model-option
Fix typo in help text for "-model" option
Fix protobuf message generation
Merge pull request #3937 from emaggiori/exp
Solving issue with exp layer with base e
Merge pull request #3942 from jeffdonahue/propagate-down-true
Net: setting `propagate_down: true` forces backprop
test_net.cpp: add TestForcePropagateDown
Merge pull request #3891 from danielgordon10/pycaffe-multi-instantiation-fix
avoid divide by zeros, suggested by SeanBell
Use lazy initialization to reuse orderd dict/list creations to save time on repeated calls.
small bug in pooling_layer.cu
Merge pull request #3821 from jreniecki/mkl
Update info about MKL licensing
upgrading InfogainLoss layer: (1) incorporating Softmax layer to make the gradeint computation robust, much like SoftmaxWithLoss layer (see: http://stackoverflow.com/a/34917052/1714410 for more information). (2) supporting loss along axis
Update Makefile: Changed MKL_DIR to MKLROOT
Merge pull request #3797 from shelhamer/travis-rm-conda
[build] travis: remove existing conda dir
Merge pull request #3292 from dgolden1/log-parse-no-test
Merge pull request #3590 from junshi15/GPUUtilities
Merge pull request #3588 from junshi15/P2psyncPrepare
Merge pull request #3613 from longjon/py-coord-map
Merge pull request #3570 from BlGene/crop-nd
split p2psync::run()
Crop: more tests and test tuning.
Crop: fixes, tests and negative axis indexing.
Extend Crop to N-D, changed CropParameter.
add CropLayer: crop blob to another blob's dimensions with offsets
add check and find GPU device utilities
[pycaffe] test coord_map
[pycaffe] align coord_map and #3570 Crop layer
[pycaffe] document, style, and complete coord_map
Merge pull request #3770 from BlGene/lint_fix
[pycaffe] add coord_map.py for computing induced coordinate transform
Merge pull request #3773 from longjon/travis-protobuf3-fix
[travis] force protobuf 3.0.0b2 for Python 3
Removed lint script reference to non-existant caffe_memcpy function.
Merge pull request #3575 from errord/fix-boost-shared_ptr-caffe-Blob-float-no-register
Merge pull request #3716 from ttdt/master
Merge pull request #3759 from vivkul/patch-1
minor mistakes removed
[example] groom multilabel notebook title, order
Merge pull request #3755 from shelhamer/fix-upgrade-proto
Merge pull request #3471 from beijbom/clean-datalayer-tutorial
Merge pull request #3756 from intelcaffe/mkl-cosmetic-imprvmnts
- doc and cmake update MKL related
refuse to upgrade net with layer/layers inconsistency
fix input field -> input layer net upgrade: only convert full defs
check all net upgrade conditions
output all logging from upgrade net tools
Finalized tutorial. Removed asyncronous layer.
Refactor and improve code style.
Added tutorial on how to use python datalayers and multilabel classification.
Don't force datum.label=0 in array_to_datum
Merge pull request #3747 from Nerei/master
NetSpec: allow setting blob names by string
Use 'six' library to ensure python3 compliance. Use '//' instead of '/' for entire division.
Merge pull request #3725 from shaibagon/drop_nd_blobs
supporting N-D Blobs in Dropout layer Reshape
Merge pull request #3740 from shelhamer/fix-docker-flags
fix flags in #3518 for nvidia-docker
Merge pull request #3518 from zalando/feature/docker_images
Add Dockerfiles for creating Caffe executable images.
Merge pull request #3211 from shelhamer/input-layer
Deprecate ForwardPrefilled(), Forward(bottom, loss) in lieu of dropping
[examples] switch examples + models to Input layers
collect Net inputs from Input layers
drop Net inputs + Forward with bottoms
deprecate input fields and upgrade automagically
add InputLayer for Net input
Merge pull request #3612 from kashefy/tied_weights_ip_transpose
Merge pull request #3715 from olesalscheider/master
Merge pull request #3703 from shaibagon/pycaffe_nd_blobs
Merge pull request #3719 from shelhamer/new-tutorial-notebooks
CMake: Do not include "${PROJECT_BINARY_DIR}/include" with SYSTEM option
[example] improve brewing logreg notebook
[example] improve fine-tuning notebook
[example] improve learning LeNet notebook
[data] get_mnist.sh rewrite; prevents prompt in tutorial notebooks
[example] improve classification notebook
removing all references to Blob.num property (that assumes Blob is 4D). Replacing it with accessing Blob.shape[0] - for Blobs with num_axes() != 4
Merge pull request #3696 from shelhamer/fix-osx-install-name
Merge pull request #3695 from shelhamer/fix-osx-elcap-cuda-link
Fix OSX El Capitan CUDA incompatibility, by adding lib to rpath
fix library install name on OSX for relative path linking
tranpose parameter added to IP layer to support tied weights in an autoencoder. Arguments to matrix multiplication function are conditioned on this parameter, no actual transposing takes place.
Merge pull request #3676 from flx42/leveldb_include_fix
Merge pull request #3687 from pra85/patch-2
Fix a typo in docs
Remove useless LevelDB include
Merge pull request #3451 from intelcaffe/cmake-clang-fix
Merge pull request #3650 from intbots/cmake-matlab-fix
bugfix for incorrect behaviour in caffe_parse_linker_libs function while extracting libflags from absolute library path with multiple (dots)
Merge pull request #3624 from drnikolaev/bvlc-print-gpu-names
Nicely prints GPU names
Merge pull request #3587 from junshi15/distribute_proto
Merge pull request #3545 from gdh1995/relative-path-for-soft-links
use relative paths on making build/tools/ links
Merge pull request #2917 from ajkl/patch-2
Merge pull request #3022 from jeffdonahue/expose-param-display-names
Merge pull request #3605 from jeffdonahue/bias-gemm-type-fix
Remove incorrect cast of gemm int arg to Dtype in BiasLayer
Merge pull request #3591 from jeffdonahue/scale-bias-layer
Merge pull request #2651 from keir/master
Make the two separate build systems clearer in the documentation
Merge pull request #3602 from jeffdonahue/rm-cuda-props
Merge pull request #2144 from tishibas/load_image-improved
Merge pull request #2810 from madan-ram/patch-2
Update mnist readme.md: scale moved to transform_param
Merge pull request #3297 from sjbrown/patch-1
Merge pull request #3132 from bwilbertz/LastIterationLoss
Remove unnecessary CAFFE_TEST_CUDA_PROP declarations
Merge pull request #3393 from kkhoot/fix-reshape
Prevent in-place computation in ReshapeLayer and FlattenLayer
Merge pull request #3496 from jeffdonahue/fix-testdatatransformer-leaks
Merge pull request #3581 from Austriker/draw-python3
Updated import to make it work with pydotplus
Merge pull request #3593 from ronghanghu/matcaffe-versioning
show Caffe's version from MatCaffe
Separation and generalization of ChannelwiseAffineLayer into BiasLayer and ScaleLayer.  The behavior of ChannelwiseAffineLayer can be reproduced by a ScaleLayer with `scale_param { bias_term: true }`.
Merge pull request #3311 from lukeyeager/bvlc/versioning
Merge pull request #3584 from graphaelli/python3-config
Version 1.0.0-rc3
Add ChannelwiseAffine for batch norm
copy proto to distribute directory
Merge pull request #3388 from mohomran/exponential_linear_units
Add makefile config option for linking Python 3 libraries
add register Net and Solver
Merge pull request #3536 from intelcaffe/im2col-speedup
Merge pull request #3574 from tahtguymike/maxpool_bug
Workaround for inplace max pooling issue
fixbug #issues/3494 No to_python (by-value) converter found for C++ type: boost::shared_ptr<caffe::Blob<float> >
Performance related update of im2col() and col2im() functions
Merge pull request #3525 from philkr/cmake_python3
Merge pull request #2865 from philkr/top_bottom_names
CMake python version fix
Merge pull request #3519 from philkr/faster_solver
Speeding up the GPU solvers
Exposing layer top and bottom names to python
TestDataTransformer: fix some memory leaks caused by use of 'new'
Merge pull request #3490 from fyu/spaceplus
remove extra space before +
Merge pull request #3487 from longjon/dilation
enable dilated deconvolution
add short description of dilation to caffe.proto
disable dilated deconvolution
add and improve tests for dilated convolution/im2col
add support for N-D dilated convolution
add support for 2D dilated convolution
Merge pull request #3468 from mnogu/blobs_lr-to-lr_mult
Replace blobs_lr with lr_mult in readme.md.
- Fix to cmake build for clang
Merge pull request #3439 from flx42/cudnn_v4
Fix CuDNNConvolutionLayer for cuDNN v4
Merge pull request #3432 from ianfhunter/patch-1
Update interfaces.md
Merge pull request #3090 from longjon/summarize-tool
Merge pull request #3395 from BonsaiAI/extract_features-compatibility
ELU layer with basic tests
Correct type of device_id; disambiguate shared_ptr
sigmoid fix (cpp)
sigmoid fix (cu)
Merge pull request #3404 from BonsaiAI/remove-hamming-dist
Remove hamming_distance and popcount
Merge pull request #3313 from gdh1995/master
Merge pull request #3267 from cbalint13/cmake-cudnn
Merge pull request #3285 from longjon/cuda-dead-cpp
Merge pull request #3315 from shelhamer/layer-headers
dismantle layer headers
Merge pull request #3378 from BonsaiAI/fix-temp-dir-creation-failure
Secure temporary file creation
Secure implementation of MakeTempDir
Merge pull request #3320 from BonsaiAI/disambiguate-dtype
Merge pull request #2693 from AdamStelmaszczyk/patch-1
Merge pull request #3361 from BonsaiAI/avoid-snprintf
Merge pull request #3352 from lukeyeager/bvlc/pytest-python-layer
Merge pull request #3389 from ronghanghu/remove-stepearly
Remove bogus stepearly in MNIST example
replace snprintf with a C++98 equivalent
Scope macros inside switch
Merge pull request #3296 from cdoersch/normalize_batch
Better normalization options for SoftmaxWithLoss layer.
Merge pull request #3363 from BonsaiAI/remove-opencv-include
Merge pull request #3362 from eelstork/patch-2
Exclude core.hpp when building without OpenCV
Function must return a value
Convert std::max args to Dtype
Merge pull request #3359 from ronghanghu/fix-accuracy-layer-top
Fix MaxTopBlobs in Accuracy Layer
Skip python layer tests if WITH_PYTHON_LAYER unset
Merge pull request #3321 from BonsaiAI/synced-mem-functions-will-return-a-value
Merge pull request #3261 from kli-nlpr/patch-1
Merge pull request #3332 from alexlee-gk/master
Fix outs and diffs being overwritten in forward_backward_all.
Merge pull request #3299 from kkhoot/fix_bn
Merge pull request #3323 from BonsaiAI/remove-unnecessary-includes
Display and store cuDNN version numbers during cmake.
Merge pull request #3328 from w1res/patch-1
Add parentheses to backward_{cpu,gpu} method.
Make backward pass work when global stats is active for BatchNormLayer including minor code cleaning
Update computation of variance and global stats in BatchNormLayer
Fix loss of last iteration when average_loss > 1
Functions shall return a value in syncedmem
Remove un-necessary includes
fix a bug that time duration may be 0 when downloading model binary
Merge pull request #3127 from lukeyeager/install-lib-permissions
Merge pull request #3235 from shelhamer/dlog-cudnn-workspace
Merge pull request #3290 from ernest-tg/master
Merge pull request #3294 from panmari/simpler_diff
Merge pull request #3295 from timmeinhardt/fix_issue_3274
Merge pull request #3310 from gustavla/contrastive-doc-fix
OSX 10.10 (and more) use Accelerate Framework instead of veclib
Merge pull request #3305 from ronghanghu/display-ignore-layer
Merge pull request #3300 from BonsaiAI/replace-unistd
Replace unistd functions with cross platform counterparts
DOC: Fix consistent typo in contrastive loss
Merge pull request #3308 from cassinaj/master
Merge pull request #1 from cassinaj/cassinaj-minor-typo-fix
Switched order of two layers for simpler diff with untuned file
Merge pull request #3303 from eelstork/patch-1
display 'ignore source layer' when initializing from existing parameters
GetDB must return a value
Add a -c to wget so that it continues interrupted downloads
Fix ArgMaxLayer::Reshape for any num of bottom axes
Don't attempt to write CSV if there are no lines to write
Correct transposition & channel_swap in deprocess
Merge pull request #3287 from longjon/travis-install-whitespace
remove dead cpp code for number of CUDA threads
[style] fix whitespace in travis_install.sh
Merge pull request #3286 from longjon/fix-py3-travis-boost
[travis] fix boost/python3 conda conflict
Merge pull request #3275 from darxriggs/master
Merge pull request #3276 from lukeyeager/bvlc/fix-travis-cmake-download
TravisCI: wget cmake with --no-check-certificate
fix detect.py (invalid model path)
Merge pull request #3082 from gustavla/pycaffe-snapshot
Update plot_training_log.py.example
Merge pull request #3254 from ronghanghu/cudnn3_accum_grad
CuDNNConvolutionLayer accumulate gradients
Merge pull request #3221 from BonsaiAI/cmake-forward-compatibility
cuDNN: only log conv workspace in debug mode
Merge pull request #3229 from cdoersch/batchnorm2
Merge pull request #3186 from lionleaf/makefile_opencv_imgcodecs
Add opencv_imgcodecs to library path in Makefile
Merge pull request #3234 from rodrigob/patch-1
diff.ndim != 4 is outdated
Cleanup batch norm layer, include global stats computation
Merge pull request #3226 from kkhoot/clean_header
Added batch normalization layer with test and examples
Merge pull request #3088 from lukeyeager/bvlc/lmdb-nolock
Clean redundant/unnecessary headers
Move HDF5 defines to data_layers header
Endorse CMP0046, CMP0054
Merge pull request #3182 from bchu/tutorial-fix
Merge pull request #3185 from mausoomsarkar/master
Merge pull request #3205 from shelhamer/test-layer-type-upgrade
[test] drop bogus OpenCV guard for layer type
Merge pull request #3218 from shelhamer/cudnn3-compatible
Merge pull request #3219 from shelhamer/install-caffe-users
[docs] cuDNN v3 compatible
installation questions -> caffe-users
Merge pull request #3217 from BonsaiAI/qualify-CUDA-status-message
Qualify messages issued by CMake when CUDA is unavailable
Moved the loop inside PReLUParamBackward to do the reduction inside the kernel Now PReLU backward is taking the same time as forward
Merge pull request #3116 from ronghanghu/solver-refactor
Merge pull request #3206 from shelhamer/net-init-logging
clean up logging for Net init
Update examples and docs
Add automatic upgrade for solver type
Change solver type to string and provide solver registry
Split solver code into one file per solver class
Merge pull request #3207 from ronghanghu/test-matcaffe-io
Test reading and writing mean proto in matlab
Merge pull request #3089 from shelhamer/groom-conv
Merge pull request #3204 from shelhamer/rearrange-upgrade-helpers
Merge pull request #3190 from DrSleep/master
Merge pull request #3189 from bchu/caffenet-mirror
rearrange upgrade helpers
Merge pull request #3160 from shelhamer/cudnnV3
Initial cuDNN v3 support
Merge pull request #3200 from lukeyeager/bvlc/fix-blobproto_to_array
Allow old-style shape in blobproto_to_array
Fixed drawing problems with repeated convolution
Merge pull request #2966 from cdoersch/batch_reindex_layer
Set CaffeNet train_val test mirroring to false
Merge pull request #3187 from akash1810/patch-1
Add pyyaml as a requirement
Merge pull request #3184 from lalelale/patch-1
Update store2hdf5.m
In 00-classification example, get correct class label index
Merge pull request #3162 from kkhoot/fix_mvn
Improve numerical stability of variance computation in MVNLayer
Merge pull request #3170 from sh1r0/pycaffe_io
Remove the 4D constraint of blobproto IO in python
BatchReindexLayer to shuffle, subsample, and replicate examples in a batch
Merge pull request #3164 from eerwitt/layer-documentation-sample-fixes
fixes BVLC/caffe#3163
NetSpec: type-check Function inputs (they must be Top instances)
Add pycaffe test for solver.snapshot()
Merge pull request #3152 from jeffdonahue/silence-backward-fix
SilenceLayer Backward bugfix (fixes #3151)
minor typo fix
Merge pull request #3058 from zoharby/master
Add a caffe.io.write_mean function to the MATLAB interface
Merge pull request #3133 from kashefy/badge
add badge for travis build and license
Merge pull request #3069 from timmeinhardt/argmax
Merge pull request #3128 from hjss06/patch-1
Fix a typo
Install libs as non-executable files
Merge pull request #3073 from ronghanghu/consistent-malloc-free
Add ALLOW_LMDB_NOLOCK build option
Re-ordering some lines in build files
Add flag on how host memory is allocated
Merge pull request #3032 from ronghanghu/ban-pythonlayer-in-parallel
Merge pull request #3118 from ducha-aiki/patch-1
Implement ArgMaxLayerTest for axis param
Generalise ArgMaxLayerTest bottom blob shape
Update ArgMaxLayer documentation for axis param
Implement ArgMaxLayer forward_cpu and reshape for axis param
Add argmax_param axis
Fix parse_log.sh against "prefetch queue empty" messages
Merge pull request #3115 from lukeyeager/fix-generate-sample-data
Fix generate_sample_data.py - bug from #2978
Merge pull request #2978 from lukeyeager/h5t_integer
Modify HDF5DataLayerTest to test H5T_INTEGER data
Allow H5T_INTEGER in HDF5 files
Merge pull request #2951 from dplarson/examples_readme_link
Merge pull request #3112 from shelhamer/test-reshape-harder
[test] TestReshape: check that shapes actually change
[test] TestReshape: expect instead of check
[test] TestReshape: check small then large
Merge pull request #3096 from longjon/fix-conv-reshape
Merge pull request #3093 from shelhamer/check-xcode-clt-version
fix broken conv/deconv reshaping caused by reading bottom shape in LayerSetUp
Merge pull request #3095 from longjon/fix-deconv-backward
fix broken DeconvolutionLayer GPU backward caused by typo
[tools] add Python script for at-a-glance prototxt summary
[build] check xcode command line tools version >= 6
mark const im2col + col2im terms
harmonize the im2col_{cpu,gpu} assignment
clarify im2col + col2im var names
Merge pull request #3083 from yanchen036/master
Merge pull request #2049 from jeffdonahue/nd-convolution
Im2col and Convolution layers support N spatial axes
Blob: add SyncedMemory shape accessor for GPU shape access
caffe.proto: generalize ConvolutionParameter to N spatial axes
refine format of switch case in solver
Expose `Snapshot` to pycaffe
Merge pull request #3081 from shelhamer/include-io-by-default
[build] include IO dependencies by default
Merge pull request #3074 from ronghanghu/show-use-cpu
Merge pull request #2523 from BonsaiAI/separate-io-dependencies
Add a comment indicating that Travis CI tests are CPU only
Fix case in CMake notices
Separate IO dependencies
Get back 'USE CPU' print for caffe train
Merge pull request #3070 from mohomran/resize_nd-image_bug
removed bug in caffe.io.resize_image when applied to Nd images
Merge pull request #3049 from seanbell/check-snapshot-prefix
Check that the snapshot directory is writeable before starting training
Merge pull request #3063 from ronghanghu/use-expectnear-in-eltwiselayertest
Merge pull request #2941 from thatguymike/MultiGPUDocs
Use EXPECT_NEAR in EltwiseLayer test
Merge pull request #3048 from seanbell/minor-string-fix
Minor: missing space in string formatting
disallow PythonLayer in Multi-GPU training
Merge pull request #3024 from danielgordon10/python-solver-fix
enabling the alternate solvers to be accessed by the python interface
Merge pull request #3026 from CDLuminate/patch-1
Merge pull request #3027 from ronghanghu/fix-accuracy-test
Fix AccuracyLayerTest for per-class accuracy.
Update extract_features.cpp
Merge pull request #3023 from jeffdonahue/param-debug-info-fix
Merge pull request #2959 from jeffdonahue/netspec-allow-non-iterable-repeated
NetSpec: don't require lists to specify single-element repeated fields
net.cpp fix debug_info params -> learnable_params
Net: expose param_display_names_
Merge pull request #3014 from jeffdonahue/trivial-slice-concat
ConcatLayer: allow trivial operation with single bottom Blob
SliceLayer: allow trivial operation with single top Blob
Merge pull request #2990 from mattdawkins/add-openblas-path
Merge pull request #3010 from darrengarvey/fixup-memory-leak-siamese
Merge pull request #3012 from lukeyeager/convert-imageset-logging
Merge pull request #3011 from darrengarvey/fixup-cifar10-example
Merge pull request #3009 from darrengarvey/cleanup-documentation-warnings
Show output from convert_imageset tool
Fix up documentation errors.
cifar10: Fix examples by setting snapshot_format.
Merge pull request #3008 from darrengarvey/cleanup-cmake-variable
Fix memory leak in convert_mnist_siamese_data.
Cleanup: Fixup capitalisation of Caffe_POSTFIX.
Merge pull request #3007 from philkr/neg_lr_mult
Compute backward for negative lr_mult
Merge pull request #2998 from longjon/data-race
Merge pull request #2894 from mfigurnov/fix-truncation-warning
fix GPU data race
Merge pull request #2989 from jyegerlehner/embed-layer-compile-warning
Fix EmbedLayer compiler warning for unused variable.
Add extra openblas search path
No need to squeeze the output of the network
Merge pull request #2944 from philkr/python_layer_param
Merge pull request #2970 from ronghanghu/spp-fix
Fix previous mistake on unimplemented top and address pyramid_height_==1 in SPPLayer
Merge pull request #2964 from jyegerlehner/mvn-layer-fixes
Merge pull request #2981 from maaskola/draw-deconvolution
Draw Deconvolution layers like Convolution layers
MVNLayer fixes.
Merge pull request #2083 from jeffdonahue/tile-layer
TileLayer: add CUDA kernels
Add TileLayer
Merge pull request #2032 from jeffdonahue/embed-layer
Merge pull request #2927 from jeffdonahue/improve-net-init-error-msgs
Merge pull request #2972 from jeffdonahue/concat-backward-fix
Python parameter test added
Allow the python layer have weight/parameter blobs.
Merge pull request #2963 from longjon/superfluous-toproto
bugfix for ConcatLayer with propagate_down set
TestConcatLayer: add gradient check for bottom[1] only (to verify propagate_down[0] == false correctness)
Merge pull request #2935 from rmanor/accuracies
Merge pull request #2253 from jyegerlehner/snapshot_on_signal
Output accuracies per class.
Add signal handler and early exit/snapshot to Solver.
remove superfluous code in Net::ToProto
Merge pull request #2949 from jeffdonahue/deconv-gpu-backward-no-repeat-im2col
Merge pull request #2950 from lukeyeager/use-input_shape
[examples] fix link to feature visualization notebook
Use input_shape instead of input_dim in examples
Merge pull request #2947 from BlGene/bdl_fixup
DeconvolutionLayer Backward_gpu fix: don't redo im2col
Merge pull request #2930 from lukeyeager/pycaffe-layer_type_list
Expose LayerFactory::LayerTypeList in pycaffe
In BasePrefetchingDataLayer::Forward_cpu hanged top[0]->Reshape to top[0]->ReshapeLike, in line with other calls.
Add information about how to get GPU topology from nvidia-smi
Add some documentation on Multi-GPU support
Merge pull request #2812 from philkr/python_loss_weight
Malloc at least 1 byte for MultiGPU P2PSync buffers
Merge pull request #2931 from ronghanghu/fix-gpu-test
Fix MultiGPU solver test with TEST_GPUID != 1
Merge pull request #2928 from cypof/lib_make_target
New make target to only build the library.
[net] improve net config and shape mismatch error messages
Exposing blob loss weight to python
Merge pull request #2925 from flx42/fix_classification_example
Make classification.bin support models with less than 5 classes
Merge pull request #2921 from buaaliyi/multi_gpu
Merge pull request #2924 from ronghanghu/fix-malloc-empty
Malloc at least one byte in Parallel
Merge pull request #2920 from PatWie/master
Merge pull request #2918 from ronghanghu/adam
Cite Adam paper in solver.hpp
Adam solver
Destroy CUDA stream when finished
information about new implemented solvers
Merge pull request #2572 from flx42/optimize_inner_product_special_case
fixing the database param
Merge pull request #2903 from ronghanghu/multi_gpu
Apply mutex only to shared layers and fix NVCC warning
Data Layers Parallel for Multi-GPU
Merge pull request #2909 from jeffdonahue/learnable-param-id-fix
Merge pull request #2891 from fyu/fix-caffenetpy
fix for learnable_param_ids_
Merge pull request #2782 from matthiasplappert/adadelta
Merge pull request #2873 from gut/master
Merge pull request #2897 from Russell91/patch-1
Update net_spec.py
Fix truncation of value warning
Clean up and modernize AdaDelta code; add learning rate support; add additional test cases
Updated AdaDelta for modern Caffe; reduced iterations on multi-iter tests
Implement AdaDelta; add test cases; add mnist examples
[docs] add multi-gpu usage note to interfaces
Detect topology corner cases and improve broadcast order
Multi-GPU
Allocate host memory through cudaMallocHost
Add DataReader for parallel training with one DB session
Persistent prefetch thread
Change the way threads are started and stopped
Thread-local Caffe
Add BlockingQueue for inter-thread communication
from __future__ imports must occur at the beginning of the file
Merge pull request #2887 from shelhamer/solver-test-data
Use net_->learnable_params() instead of net_->params() in RMSprop
Merge pull request #2888 from ronghanghu/rms-prop-fix-tests
Encapsulate kRMSDecay in solver tests
Merge pull request #2867 from ronghanghu/rms-prop
Implement RMSProp Solver
TestGradientBasedSolver: replace dummy data with hdf5
TestGradientBasedSolver: drop doubled seed inititialization
EmbedBackward with no loops -- use caffe_gpu_atomic_add instead
Add EmbedLayer for inner products with sparse input (one-hot vectors), with unit tests
test_gradient_check_util: check_bottom < -1 only checks params
Add gpu_util.cuh, with caffe_gpu_atomic_add
Merge pull request #2813 from longjon/net-spec-imp
Merge pull request #2886 from jeffdonahue/master
temporarily switch the snapshot_format default back to BINARYPROTO
Merge pull request #2877 from jeffdonahue/pycaffe-shape-accessor
Merge pull request #2866 from jeffdonahue/fix-weight-sharing
Net: add learnable_params_ used by solvers to correctly handle shared params
TestGradientBasedSolver: make tests across solver types more consistent
TestGradientBasedSolver: restore Gaussian filler to all tests except accumulation one
Merge pull request #2836 from erictzeng/hdf5_snapshot
Update example bash scripts to expect .h5, new extensions in .gitignore
TestSnapshot expects .h5 snapshots, explicitly checks history.
Snapshot model weights/solver state to HDF5 files.
pycaffe: add shape accessor
Merge pull request #2884 from tianzhi0549/patch-1
TestGradientBasedSolver: add TestSnapshot to verify behavior when restoring net/solver from snapshot
add double_data, double_diff to BlobProto for weights/snapshots saved when using Dtype == double
Merge pull request #2634 from mlopezantequera/patch-2
add [] to "delete pixels".
Merge pull request #2880 from koki0702/typo
Fix typo
Merge pull request #2871 from shelhamer/python-layer-arg
PythonLayer takes parameters by string
Merge pull request #2876 from shelhamer/fix-py-include
[pytest] open exception file with mode for python3
[pycaffe,build] include Python first in caffe tool
Fix download model binary script to get correct lines on parsing table
Fix download model script to use zip archive
Merge pull request #2462 from longjon/correct-python-exceptions
Merge pull request #2859 from philkr/image_data
ImageData layer default batch size of 1, and check for zero batch size
Merge pull request #2583 from lukeyeager/fix-log-levels
Change log levels in upgrade_proto
Merge pull request #2837 from longjon/contributing-file
[docs] add CONTRIBUTING.md which will appear on GitHub new Issue/PR pages
[docs] fix contrastive loss eq
[docs] fix lmdb fetch url and path
[docs] clear up PYTHONPATH confusion
[pytest] simple test of top-less layers
[pycaffe] net spec layers can have ntop=0
[pycaffe] allow layers to have names different from their first tops
[pycaffe] add Top._to_proto convenience function
[pycaffe] use a Counter instead of a dict for counting net spec names
[pycaffe] remove dead code
Merge pull request #2807 from Franck-Dernoncourt/patch-1
Fix path to mnist_autoencoder.prototxt
[docs] set lmdb url to github mirror
[docs] matlab 2015a compatible
Merge pull request #2740 from philkr/travis_python3
Travis scripts for python3 and pytest for cmake. Also fixes CUDA CMake build issue #2722.
[examples] fix link to point to new tutorial notebook
Merge pull request #2762 from kashefy/fix_method_doc
tiny fix in Layer::Backward documentation
Merge pull request #2739 from AdamStelmaszczyk/patch-2
Merge pull request #2748 from glebm/patch-1
Merge pull request #2750 from yosssi/patch-1
Update net_layer_blob.md
examples/imagenet: fix broken link
Merge pull request #2742 from philkr/absval_warning
Removes a unused variable warning
One command less
Merge pull request #2712 from semitrivial/master
Merge pull request #2714 from philkr/python3_netspec
Making the net_spec python3 compatible
Merge pull request #2716 from lukeyeager/cmake-typos
Fix CMake typos
List protobuf-compiler dependency in the correct place (it is in the package managers for both 14.04 and 12.04)
Deprecated OpenCV consts
Merge pull request #2676 from lukeyeager/update-docs-boost
Optimize inner product layer for special case M == 1
Update installation docs for boost - close #2454
Merge pull request #2213 from tnarihi/bilinear-upsampling-filler
bilinear filler -- useful for interpolation with DeconvolutionLayer
Merge pull request #2667 from BVLC/tutorial
[examples] add Euclidean loss PythonLayer
[examples] sequence and revise notebooks
[examples] flickr fine-tuning notebook
[examples] draft Python solving example
Merge pull request #2086 from longjon/python-net-spec
[pytest] minimal testing of net specification
[examples] caffenet python spec
[pycaffe] basic net specification
Merge pull request #2611 from dpaiton/test_net_bugfix
copyright 2015
Merge pull request #2579 from lukeyeager/draw-fix
Merge pull request #2636 from berleon/master
fixed _force_color check, fixes #2635
Update parse_log.py
Merge pull request #2609 from lukeyeager/doc-fixes
register a dummy reducer to prevent mincepie runtime error
fixed two bugs with prototext format
Fix HTML display for docs
Merge pull request #2605 from ajschumacher/patch-2
typo: "a fixed steps" to "at fixed steps"
Merge pull request #2278 from sguada/db_split
[docs] drop out-of-date reference to dev branch
Small platform-specific bugfix for draw.py
Split db.hpp into leveldb_db.hpp and lmdb_db.hpp
Merge pull request #2551 from ShaggO/loglayer
LogLayer gpu functionality moved to .cu file
[bug] fix double instantiation of GPU methods in LogLayer
Merge pull request #2089 from jeffdonahue/reduction-layer
Add ReductionLayer to reduce any number of "tail" axes to a scalar value
Merge pull request #2082 from jeffdonahue/flatten-layer-axis
FlattenLayer gets a FlattenParameter with an axis, end_axis
Merge pull request #2090 from jeffdonahue/log-layer
Add LogLayer
Merge pull request #2054 from mtamburrano/filter_layer_rebased
FilterLayer cleanup and bugfix for GPU backward
Filter Layer implemented
Merge pull request #2532 from shelhamer/accum-prelu
Merge pull request #2536 from kibum14/master
Remove unnecessary filler parameter in the sample model
PReLU accumulates grad
Merge pull request #2245 from dwt/add_homebrew_comments_to_makefile_config_example
Merge pull request #2064 from drohit92/patch-1
Merge pull request #2163 from jeffdonahue/slice-concat-kernels
Merge pull request #2107 from 5kg/fix_mac_doc
Merge pull request #2400 from cnDelbert/master
Merge pull request #2350 from drdan14/log-parser-python-improved
Merge pull request #2522 from MartinThoma/moose
Merge pull request #2498 from flx42/cpp_classification_example
Merge pull request #2528 from shelhamer/travis-lmdb-git
Merge pull request #2527 from ronghanghu/matcaffe-update-mean-format
[travis] install lmdb through git mirror
Update ilsvrc_2012_mean.mat to W x H x C, update demo and add comments
Merge pull request #2511 from flx42/fix_illegal_mode_changes
Merge pull request #1977 from shelhamer/accum-grad
Add a simple C++ classification example
Merge pull request #2410 from sguada/datum_transform
 Merge pull request #2294 from TorosFanny/master
[example] fix path for diff in net surgery
Merge pull request #2240 from nsubtil/cmake-build-dependencies
Merge pull request #2468 from Nerei/feature/minor_fix_in_cmake_config_generation
Merge pull request #2493 from longjon/sketchy-cuda-kernel-loop
Merge pull request #2514 from norouzi/master
Merge pull request #2505 from ronghanghu/matcaffe3
More tests for Blob, Layer, copy_from and step, fix some typos
Fix automatic header file dependency for MatCaffe
Move demo to demo/ and check weights file existence
Clean up old matcaffe wrapper and rename caffe.reset to caffe.reset_all
Add MatCaffe docs to docs/tutorial/interfaces.md
Aesthetic changes on code style and some minor fix
Fix matlab tailing dimension 1 issue for shape match
MatCaffe3 : a powerful matlab interface for caffe
directly normalize accumulated gradients
test equivalence of solving with accumulating gradients
python/draw_net.py and python/caffe/draw.py: Simplified code; added more docstrings; adjusted code according to PEP8
adjust local learning rate and decay according to gradient accumulation
accumulate gradients in cudnn conv layer
accumulate gradients in (de)conv layers
accumulate gradients in inner product layer
zero-init param diffs in gradient checker
zero-init param diffs and accumulate gradients
Merge pull request #2518 from shelhamer/dedup_solvers
Solver::MakeUpdate() -> Solver::ApplyUpdate
fix the bug with db_type when the number of features to be extracted is larger than 1
deduplicate decay and local rate in solver updates
Refactor solvers regularization and logging code
add leading zeros to keys in feature DB files
Make class MultinomialLogisticLossLayerTest derive from CPUDeviceTest
Make class CuDNNSoftmaxLayerTest derive from GPUDeviceTest
Make class DummyDataLayerTest derive from CPUDeviceTest
Make class CuDNNPoolingLayerTest derive from GPUDeviceTest
Make class CuDNNConvolutionLayerTest derive from GPUDeviceTest
Make class ArgMaxLayerTest derive from CPUDeviceTest
Make class CuDNNNeuronLayerTest derive from GPUDeviceTest
Make class AccuracyLayerTest derive from CPUDeviceTest
Make class Im2colKernelTest derive from GPUDeviceTest
Add classes GPUDeviceTest and CPUDeviceTest.
Split class StochasticPoolingLayerTest into CPUStochasticPoolingLayerTest and GPUStochasticPoolingLayerTest
Merge pull request #1946 from nickcarlevaris/msra_init
include comment on Saxe and sqrt(2) scaling factor
Added MSRAFiller, an Xavier-like filler designed for use with ReLUs
Split class MathFunctionsTest into CPUMathFunctionsTest and GPUMathFunctionsTest
Refactor types FloatCPU and DoubleCPU into a new type CPUDevice<T>
Merge pull request #2486 from tiangolo/ipython-notebook-v4
Update python/requirements.txt to have ipython>=3.0.0
more const in LRN layer CUDA kernels
more const in pooling layer CUDA kernels
avoid dangerous state in LRN layer CUDA kernels
avoid dangerous state in pooling layer CUDA kernels
Merge pull request #2488 from kibum14/master
fix typos in docs
Merge pull request #2484 from ronghanghu/fix-caffe-test
Merge pull request #2482 from longjon/clean-message-comments
Update IPython Notebooks to version 4
fix blob_loss_weights index in test() in caffe.cpp
clean up redundant message comments
Merge pull request #2466 from ducha-aiki/mvn-less
Merge pull request #2095 from mtamburrano/skip_propagate_down_param
Merge pull request #2467 from MartinThoma/moose
minor fix in cmake.config generation - do not force client libs to include numpy include dirs
Python: Formatted docstrings to numpydoc (Take, Give -> Parameters, Returns)
Remove unnecessary variance computation from backward in MVN layer
Added "propagate_down" param to LayerParameter
Merge pull request #2274 from Ashwani001/patch-1
[pytest] check that Python receives (correct) exceptions from Python layers
print Python exceptions when using Python layer with the caffe tool
[pycaffe] correct exceptions from Python; remove PyErr_Print
Update generate_sample_data.py
Merge pull request #2201 from jeffdonahue/tutorial-fixes
Update docs for ND blobs (#1970) and layer type is a string (#1694)
Merge pull request #2217 from jeffdonahue/ssafar-reshape-rebase
Add ReshapeParameter axis and num_axes to reshape only a particular span of the input shape
basic tests (Forward, Gradient) for ReshapeLayer
ReshapeLayer fixups for ND blobs
Added a Reshape layer for copying-free modification of blob dimensions.
Merge pull request #2177 from pgao/spp_layer
Spatial Pyramid Pooling Layer
Merge pull request #2115 from longjon/bogus-cross-entropy-gpu
remove bogus implementation of SigmoidCrossEntropyLossLayer::Forward_gpu
Merge pull request #1969 from tnarihi/fix-empty-param_name
Merge pull request #2168 from longjon/spurious-net-includes
Merge pull request #2165 from longjon/auto-reshape
Merge pull request #2072 from jeffdonahue/final-snapshot-off-by-one
Merge pull request #2456 from longjon/python-layer-object
Merge pull request #2457 from longjon/superfluous-destructors
remove superfluous empty destructors
[pycaffe] use bp::object instead of PyObject* for self in Python layer
Merge pull request #2321 from nickcarlevaris/contrastive_loss_fix
Merge pull request #2441 from gustavla/py3-fix
Merge pull request #2443 from MartinThoma/master
python: PEP8; changed docstring documentation style to NumPyDoc style
This imports the wrong io module in Python 3.
Merge pull request #2426 from longjon/check-blob-overflow
check that count_ does not overflow in Blob::Reshape
Merge pull request #2414 from tnarihi/fix-prelu-redanduncy
Modify for better readability regarding temporary bufffer for backward computation
Fix redundancy of parameter backward computation
Added support for original implementation, using (margin - d^2), through the legacy_version parameter.
Merge pull request #2369 from jeffdonahue/makefile-link-bugfix
Makefile bugfix: OTHER_BUILD_DIR name set incorrectly when empty due to lazy variable expansion when using the `?=` operator -- change them to explicit empty string checks with simple assignment operator `:=`.
Merge pull request #2393 from Nerei/feature/minor_cmake_fix
Correct the REPO_DIRNAME
minor cmake fix - now Caffe complains when cmake is executed if glog/gflags are not found.
Merge pull request #2365 from wakamori/fix_typo_in_gnuplot_example
Import Pandas in HDF5 IPython notebook. Fix for issue BVLC/caffe#2247
Merge pull request #2370 from gdh1995/master
Net::Update: CPU_ONLY is in wrong place
fix a typo that GFLAGS_GFLAGS_H_ -> GFLAGS_GFAGS_H_
fix typo: swap the titles of xlabel and ylabel
Merge pull request #2352 from pgao/rcnn-fix
Merge pull request #2330 from flx42/include_config_file_check
clarify Makefile.config check
Fix RCNN model fetching script
Improvements to python log parser
added epsilon to prevent possible division by zero in gradient calculation
Abort Makefile parsing if the configuration file cannot be found.
set default DISTRIBUTE_DIR -- fix #2328
Fixed contrastive loss layer to be the same as proposed in Hadsell et al 2006
Merge pull request #2295 from akiomik/patch-1
improved installation for osx
Simplify image_data_layer reshapes by letting data_transformer do the job.
Simplify data_layer reshapes and encodings by letting data_transformer do the job.
Added InferBlobShape to data_transformer.
Allow Transform of encoded datum. Allow initialize transformed_blob from datum or transform params. Allow force_color and force_gray as transform params.
Merge pull request #2287 from eerwitt/web-demo-import
Changing Image import to be imported from PIL.
Update generate_sample_data.py
[docs] switch lmdb url for manual install, tweak formatting
Add commented out helpers for homebrew users
Build gflags and glog through CMake if not found in the system
Merge pull request #2224 from small-yellow-duck/master
Merge pull request #2231 from tnarihi/fix-travis-miniconda
Fix: libm.* doesn not exist
Check if CPU_ONLY is set when determining CUDA version
Merge pull request #2192 from lukeyeager/remove-scikit-learn
Merge pull request #2199 from lukeyeager/downgrade-pillow
Merge pull request #2211 from nsubtil/fix-cudnn-algo
Fallback to different cuDNN algorithm when under memory pressure
Downgrade Pillow pip requirement
Merge pull request #2160 from TorosFanny/master
Add note in example about installing scikit-learn
Remove scikit-learn dependency
Merge pull request #2038 from shelhamer/cudnn-r2
note cuDNN v2 convolutional TODOs
cuDNN pooling can pad now
replace cuDNN alphas and betas with coefficient values
switch to cuDNN R2
Merge pull request #2178 from Lewuathe/typo-in-docs
Typos in documents
remove spurious net.hpp includes
always call Layer::Reshape in Layer::Forward
CUDA kernels for {Slice,Concat}Layer
change resorce to resource
Merge pull request #1922 from erictzeng/lrn_large_region_fix
improved to load RGB image as grayscale image
Merge pull request #2127 from kentashoji/fix-python-classify
Fix invalid syntax
Fix for solver issue pointed out by @moskewcz in #1972
HDF5DataLayer: remove redundant shuffle
Merge pull request #2118 from jeffdonahue/PatWie-shufflehdf5
HDF5DataLayer shuffle: minor cleanup; clarification in HDF5DataParameter
shuffle data
[docs] Remove `--fresh` Homebrew option
[docs] Add missing command in OS X installation guide
Merge pull request #1940 from tnarihi/prelu2
PReLU Layer and its tests
[docs] open release of BVLC models for unrestricted use
Remove Gist from BVLC GoogleNet
Merge pull request #2076 from jeffdonahue/accuracy-layer-fixes
AccuracyLayerTest: add tests for ignore_label and spatial axes
AccuracyLayer: add ignore_label param
Fixup AccuracyLayer like SoftmaxLossLayer in #1970 -- fixes #2063
Merge pull request #2058 from shelhamer/py-fixes
[example] pycaffe classification downloads the model automatically
Merge pull request #2066 from caotto/leveldb_include_update
Increment iter_ before snapshotting, remove +1 logic -- fixes final snapshot being off by one
SoftmaxLossLayer fix: canonicalize input axis
[example] warm-start web demo
[example] revise hdf5 classification
[example] revise net surgery + add designer filters
[example] revise filter visualization
[pycaffe] align web demo with #1728 and #1902
[pycaffe] classifier + detector only have one input
[pycaffe] fix CPU / GPU switch in example scripts
[pycaffe] make classify.py print input + output file paths
[pycaffe] no need to squeeze output after #1970
Merge pull request #1457 from jyegerlehner/preserve-extracted-blob-shapes
extract_features preserves feature shape
Merge pull request #1456 from jyegerlehner/load-weights-from-multiple-caffemodels
Load weights from multiple caffemodels.
whitespace in common.hpp
comment grammar in net.cpp
Update leveldb include variable name to match FindLevelDB.cmake
Update readme.md
Fix references to plural names in API documentation
Merge pull request #1987 from tnarihi/fix-siam-example
Merge pull request #2059 from philkr/python_layer_cmake
Merge pull request #2056 from philkr/hdf5
Merge pull request #2055 from tishibas/iss1506
Making python layer work with cmake
Merge pull request #2010 from danielhamngren/update_python_requirements
Merge pull request #2037 from shelhamer/expose-solver-restore
fix #1506
Adding correct hdf5 path
[docs] include boost-python in OSX pycaffe install
[pycaffe] add missing import sys
expose Solver::Restore() as public and Solver.restore() in pycaffe
[pycaffe] check mean channels for transformation
Merge pull request #2035 from jeffdonahue/include-climits
include/caffe/common.hpp: add <climits> for INT_MAX (now in blob.hpp)
fix comment I forgot about from @shelhamer's review of #1970
Merge pull request #2031 from NVIDIA/image_mean
Add error checking for image mean
Merge pull request #1966 from philkr/python_fixes
Merge pull request #1970 from jeffdonahue/tensor-blob
[pytest] use non-4d blobs in test_python_layer
[pycaffe] expose Blob.reshape as *args function
Add option not to reshape to Blob::FromProto; use when loading Blobs from saved NetParameter
PyBlobs support generalized axes
Add CHECK_EQ(4, ...)s to "vision layers" to enforce that the num/channnels/height/width indexing is valid.
DummyDataLayer outputs blobs of arbitrary shape
EuclideanLossLayer: generalized Blob axes
WindowDataLayer outputs 1D labels
ImageDataLayer outputs 1D labels
MemoryDataLayer outputs 1D labels
DataLayer outputs 1D labels
HDF5DataLayer shapes output according to HDF5 shape
SplitLayer: change Reshape(n,h,c,w) to ReshapeLike(...)
SoftmaxLossLayer generalized like SoftmaxLayer
CuDNNSoftmaxLayer: generalized Blob axes
SoftmaxLayer: generalized Blob axes
SliceLayer: generalized Blob axes
ConcatLayer: generalized Blob axes
TestConcatLayer: add forward/gradient tests for concatenation along num
TestConcatLayer: fix style errors
common_layers.hpp: remove unused "Blob col_bob_"
FlattenLayer: generalized Blob axes
EltwiseLayer need not assume old 4D dim names
Test{Net,Solver} fixes for AccuracyLayer generalization
AccuracyLayer generalized to N instance axes
AccuracyLayer output is 0D (scalar)
LossLayer output is 0D (scalar)
ConvLayer biases are 1D
InnerProductLayer can multiply along any axis
Fix sparse GaussianFiller for new IPLayer weight axes
InnerProductLayer weights are 2D; biases are 1D
TestBlob: test that legacy BlobProtos are correctly handled by ShapeEquals
add offset, {data,diff}_at nd blob accessors
Add BlobShape message; use for Net input shapes
Blobs are ND arrays (for N not necessarily equals 4).
Added Pillow to requirements.txt
Merge pull request #1999 from boechat107/patch-2
Fix siamese ipynb example
Merge pull request #1955 from philkr/reshaping_encoded
Fix incorrectly storing empty param_name
Small fix (visualization) on SLICE layer's documentation
Fixing two bugs related to python3 and PROJECT_SOURCE_DIR
Merge pull request #1960 from gustavla/makefile_fix
Merge pull request #1961 from sergeyk/master
Makefile fix for OS X 10.10
Replaced illegal tab in Makefile with spaces.
fixed matcaffe printout to specify num of args (now including train/test phase)
Decoding the datum before feeding it into the reshaping data layer
Merge pull request #1923 from philkr/python3_master
Making python3 work with cmake and the new python wrapper
Merge pull request #1926 from shelhamer/test-caffe-tool
Merge pull request #1941 from jsupancic/cpp_lint_python2
Merge pull request #1948 from spmallick/patch-1
APPLE was misspelled. in Line 27
Merge pull request #1939 from Nerei/bugfix/install_rpath_for_pycaffe
cpp_lint.py fails silently with Python3 (which is the default on some systems). This commit specifies Python2 with which cpp_lint.py works :-)
minor cmake sumamry log fix
fixed bug in install-tree: _caffe.so installed by install(TARGET ...) was overwritten with symlink created at build time and installed with install(DIRECTORY ...)
set proper CMAKE_INSTALL_RPATH for _caffe.so and tools
ignore pycharm files
check caffe tool runs in runtest
Bounds checks for cross-channel LRN.
Add failing tests for LRNLayer due to large local region
Merge pull request #1921 from shelhamer/fix-tool-linking
[build] fix dynamic linking of tools
Merge pull request #1914 from eerwitt/master
Updated the path for get_ilsvrc_aux.sh to match what is found in the current project
Merge pull request #1849 from BVLC/next
Correct 'epochs' to 'iterations'
Brief explanation of SLICE layer's attributes
[docs] add check mode hint to CPU-only mode error
[docs] send API link to class list
[build] fix rpath for examples
Merge pull request #1910 from philkr/encoded
Repeal revert of #1878
[docs] add gitter chat badge
added a force_encoded_color flag to the data layer. Printing a warning if images of different channel dimensions are encoded together
Revert "Merge pull request #1878 from philkr/encoded"
Merge pull request #1907 from shelhamer/memory-warn-transform
relax MemoryData transform check to warning
Merge pull request #1899 from philkr/project_source_dir
Merge pull request #1902 from shelhamer/py-stopgap
[pycaffe] switch examples to Transformer
[pycaffe] take pre-processing from Net and give to Transformer
[pycaffe] import newline cleanup
Changing CMAKE_SOURCE/BINARY_DIR to PROJECT_SOURCE/BINARY_DIR
comment fix: Decaf -> Caffe
[pycaffe] fix bug in Python layer setup
Merge pull request #1790 from shelhamer/net-phase
[matcaffe] give phase to Net
[pycaffe] give phase to Net
tools make net with phase
construct Net from file and phase
no phase for the solver to orchestrate
pass phase to transformer through layer
give phase to Net and Layer
Merge pull request #1703 from longjon/pyreformation
Merge pull request #1887 from shelhamer/docs
[make] link libcaffe.so before dependencies
[docs] explain one true branch and dev workflow
[docs] update and split installation
switch to V2 proto definitions for pytest
[travis] enable Python layer for testing
except PythonLayer from layer factory test
add WITH_PYTHON_LAYER build option to include Python layer
[pytest] basic test of Python layer
[pytest] test that get_solver runs
[pycaffe] allow Layer to be extended from Python
LayerRegistry uses shared_ptr instead of raw pointers
[pycaffe] re-expose SGDSolver, and expose other solvers
[pycaffe] re-expose Layer
[pycaffe] re-expose Blob
[pycaffe] re-expose Net
[pycaffe] expose global ("Caffe::") functions
[pycaffe] strike down wrappers, momentarily gut all functionality
[pycaffe] enable numpy API deprecation warnings
Merge pull request #1842 from shelhamer/dynamic-linking
[docs] groom index and zoo for highlights
[docs] Caffe is by the BVLC, created by Yangqing, and brewed by Evan
[docs] include caffeine favicon for site
only dynamically link the tests
dynamic linking
[docs] README dispatch
Merge pull request #1878 from philkr/encoded
[docs] note new CMake build
Merge pull request #1667 from Nerei/feature/cmake_well_done
cmake 2.8.7. support
[travis] proper cmake params
opencv 3.0 compilation (replace #1714)
improve CMake build
ignore qtcreator files
Cleaning up the encoded flag. Allowing any image (cropped or gray scale) to be encoded. Allowing for a change in encoded (jpg -> png vice versa) and cleaning up some unused functions.
Merge pull request #1313 from shelhamer/reshape-data-layer
test reshaping DATA and IMAGE_DATA
reshape DATA + IMAGE_DATA for inputs of varying dimension
Merge pull request #1884 from tnarihi/fix-python-draw
Fix `draw` to support new protobuf format
Merge pull request #1879 from bamos/patch-1
Correct 'epochs' to 'iterations'
Fix  Draw Net Problem #1709 Introduced by  Layer type is a string #1694
Merge pull request #1874 from jeffdonahue/blob-math-test-precision
BlobMathTest: fixes for numerical precision issues
Merge pull request #1757 from jeffdonahue/clip-grads
Add gradient clipping -- limit L2 norm of parameter gradients
add Net::param_owners accessor for param sharing info
Blob: add scale_{data,diff} methods and tests
SoftmaxWithLossLayer fix: takes exactly 2 bottom blobs (inherited from LossLayer)
Merge pull request #1841 from shelhamer/no-memory-or-hdf5-transform
Merge pull request #1851 from jeffdonahue/cudnn-layer-factory-test-fix
Fixes for CuDNN layers: only destroy handles if setup
Merge pull request #1838 from DmitryUlyanov/dev
HDF5_DATA + MEMORY_DATA refuse loudly to transform
Allow using arrays with n_ * size_ > 2^31
Merge pull request #1416 from mtamburrano/matVector
groom #1416
removed needs_reshape_ and ChangeBatchSize is now set_batch_size
small fixes
MemoryDataLayer now correctly consumes batch_size elements
MemoryDataLayer now accepts dynamic batch_size
Added opencv vector<Mat> to memory data layer with tests
Merge pull request #1789 from SaganBolliger/softmax_loss_gpu
Added GPU implementation of SoftmaxWithLossLayer.
Merge pull request #1837 from shelhamer/image-fail-die
Merge pull request #1840 from shelhamer/fix-power-test
reduce step size in PowerLayer gradient checks: fix #1252
build with libc++ on Yosmite with CUDA 7
Merge pull request #1836 from jeffdonahue/loss-param-upgrade-fix
fix for layer-type-str: loss_param and DECONVOLUTION type should have been included in V1LayerParameter, get upgraded
die on inputs to IMAGE_DATA that fail to load
Merge pull request #1694 from jeffdonahue/layer-type-str
Upgrade existing nets using upgrade_net_proto_text tool
start layer parameter field IDs at 100
get rid of NetParameterPrettyPrint as layer is now after inputs (whoohoo)
add message ParamSpec to replace param name, blobs_lr, weight_decay, ...
add test that all V1 layer type enum values upgrade to valid V2 string types
add v1 to v2 upgrade tests
restore test_upgrade_proto to dev version
automagic upgrade for v1->v2
restore upgrade_proto
'layers' -> 'layer'
Add unit test for LayerRegistry::CreateLayer
DataLayer and HDF5OutputLayer can be constructed and destroyed without errors
Layer type is a string
fix Nesterov typo found by @bamos
fixed small bug: output label_file -> label_filename
add space after "Loading mean file from"
fix GoogLeNet license overwritten by back-merge (see #1650)
Merge pull request #1615 from longjon/deconv-layer
Merge pull request #1817 from boechat107/patch-1
lint 1f7c3de
Brief explanation of SLICE layer's attributes
Merge pull request #1748 from longjon/db-wrappers
Merge pull request #1794 from shelhamer/no-dump-net
Merge pull request #1654 from longjon/softmax-missing-values
Merge pull request #1753 from jeffdonahue/enhance-debug-info
debug_info in NetParameter so it can be enabled outside training
debug_info: print param (and gradient) stats for whole Net after Backward
Add BlobMathTest with unit tests for sumsq and asum
Blob: add sumsq_{data,diff} methods
Enhancements for debug_info to display more information.
[docs] add check mode hint to CPU-only mode error
[docs] send API link to class list
[test] gradient checks for softmax ignore_label and normalize: false
document the loss_param options to SoftmaxWithLossLayer
[test] simple test for DeconvolutionLayer
document DeconvolutionLayer
Merge pull request #1555 from drdan14/draw-net-improvements
Merge pull request #1632 from 7hil/cifar_lmdb
Merge pull request #1746 from dj1989/mat_hdf5_demo
Merge pull request #1755 from jeffdonahue/softmax-optimization
[pycaffe] de-dupe imports
[example] lenet early stopping -> mnist examples
Merge pull request #1754 from jeffdonahue/softmax-loss-fix
[docs] ask install + hardware questions on caffe-users
clarify draw_net.py usage: net prototxt, not caffemodel
drop dump_network tool
Merge pull request #1787 from shelhamer/pytest-caffe-set
[fix] align pytest for solver with #1728
Merge pull request #1786 from xianjiec/dev
fix bugs by adding const
Merge pull request #1473 from longjon/pytest
hdf5_save_nd_dataset takes a const string& (instead of const string)
SoftmaxWithLossLayer: use CreateLayer so that a CuDNNSoftmaxLayer is created if available
Back-merge fixes + docs
Unroll kernels in SoftmaxLayer...from terrible performance to mediocre performance.
Merge pull request #1756 from jeffdonahue/max-total-bytes-limit
SetTotalBytesLimit to the max (2 GB minus 1 byte)
gut dataset wrappers
test db wrappers
use db wrappers
add db wrappers
Merge pull request #1747 from yosinski/doc-up
Updated doc to suggest boost 1.57
Matlab demo for Caffe-compatible HDF5 read/write
Merge pull request #1434 from pcampr/patch-1
Make comments for sparse GaussianFiller match actual behavior
Update interfaces.md file
Merge pull request #1388 from rohitgirdhar/cifar_docu_bug
Merge pull request #1704 from longjon/friendlier-link-messages
[docs] OpenCV version >= 2.4
Merge pull request #1705 from longjon/origin-rpath
Merge pull request #1686 from longjon/net-const
Merge pull request #1662 from seanbell/fix-python-resize_image
Merge pull request #1728 from shelhamer/pycaffe-mode-phase-device
check for enough args to convert_imageset
Merge pull request #1236 from mlapin/legacy_nvcc_support
Merge pull request #1740 from shelhamer/yosemite-makefile
lint internal thread
Merge pull request #1335 from ryotat/master
support OS X Yosemite / 10.10
set mode, phase, device in pycaffe; fix #1700
Merge pull request #1724 from pannous/wtf
Message: Please ask usage questions and how to model different tasks on the caffe-users mailing list
add DeconvolutionLayer, using BaseConvolutionLayer
rewrite ConvolutionLayer to use BaseConvolutionLayer helpers
add CPU_ONLY ifdef guards to BaseConvolutionLayer
add BaseConvolutionLayer
[build] specify RPATH using $ORIGIN
[build] more meaningful messages for link commands
fix typo in layer_factory.cpp
improve const-ness of Net
BVLC models are for unrestricted use (follow-up to #1650)
[pycaffe] basic, partial testing of Net and SGDSolver
[travis] run pytest
[travis] remove unneeded Makefile.config sed hacking
add "make pytest" for running Python tests
Merge pull request #1228 from longjon/solver-step
[pycaffe] expose SGDSolver.step
break out Step from Solver
Merge pull request #1650 from shelhamer/unrestricted-bvlc-models
clean up formatting in SoftmaxLossLayer
add spatial normalization option to SoftmaxLossLayer
add missing value support to SoftmaxLossLayer
fixed resize_image for the case of constant images
Merge pull request #1661 from longjon/init-test-labels
[tests] don't use Gaussian labels in NetTest's TinyNet
Merge pull request #1658 from jeffdonahue/make-everything-tweaks
don't do runtest as part of 'make everything'
only build matcaffe as part of 'make everything' if MATLAB_DIR is set
Merge pull request #1656 from longjon/fix-softmax-loss-stubs
Merge pull request #1449 from mprat/patch-1
remove SoftmaxLossLayer CPU_ONLY stubs, since there is no GPU version
Merge pull request #1655 from longjon/softmax-loss-todo
move softmax loss GPU todo comment to header file
Merge pull request #1648 from longjon/find-warnings
[docs] open release of BVLC models for unrestricted use
[docs] groom model zoo intro + list
Merge pull request #1561 from longjon/pretty-build
[scripts] fix find warnings in upload_model_to_gist.sh
Better instructions for updating Homebrew after modifying formulae
Merge pull request #1612 from sguada/googlenet_master
Merge pull request #1645 from longjon/remove-get-layer
remove unused GetLayer function (replaced by LayerRegistry::CreateLayer)
pretty the build with the Q variable
Merge pull request #1472 from longjon/incremental-build
automatic dependency generation
Merge pull request #1636 from longjon/get-layer-gone
update use of GetLayer -> LayerRegistry::CreateLayer
Merge pull request #1585 from longjon/check-malloc
switch cifar10 example to lmdb
Warning of fallback only the first time for cudnn_pooling_layer
Merge pull request #1607 from kjkjava/master
Added credits and bvlc_googlenet to model_zoo.md
Added credits for training bvlc models
Added bvlc_googlenet prototxt and weights
Fix init current_step
Adapt lenet_multistep_solver.prototxt to current solvers
Added Multistep, Poly and Sigmoid learning rate decay policies
Display averaged loss over the last several iterations
Merge pull request #1608 from sguada/added_credits
Added credits and bvlc_googlenet to model_zoo.md
Added credits for training bvlc models
Merge pull request #1598 from sguada/bvlc_googlenet
Added bvlc_googlenet prototxt and weights
Fix minor typos in strings.
Use valid MathJax delimiters.
Merge pull request #1551 from schenker/fix_image_data_layer_segfault
Add CHECKs to prevent segfault for incorrect IMAGE_DATA layers.
check host malloc result
Merge pull request #1558 from hojonathanho/hdf5_error_msg
move cuda output from build/.../.cuo -> build/cuda/.../.o
automatic discovery of source directories
consolidate build rules for object files
remove extra blank line
Check input line count in HDF5 data layer
Improvements to network drawing
Merge pull request #1384 from CellScope/log-parser-python
Store data in lists of dicts and use csv package
Take train loss from `Iteration N, loss = X` lines
Created parse_log.py, competitor to parse_log.sh
Merge pull request #1406 from CellScope/matcaffe-osx-fix-crash-on-error
Merge pull request #1516 from drdan14/update-homebrew-install-instructions
Merge pull request #1527 from drdan14/classify-py-mean-dims
clarify #endif comment
compile for compute capability 5.0
Update mean file help
Better instructions for updating Homebrew after modifying formulae
Merge pull request #1505 from longjon/conv-dedup
remove redundant code in ConvolutionLayer::Reshape
Merge pull request #1455 from seanbell/tanh-fix
Merge pull request #1469 from longjon/label-lower-bound
use DCHECK in SoftmaxLossLayer so that bounds checking has no perf penalty without DEBUG
in SoftmaxLossLayer, check label >= 0 in addition to upper bound
Fixed header order to satisfy linter
fixed tanh to not return NaN for input values outside the range [-40, 40]
Update python requirements.txt
fixed filename in build_docs.sh
Merge pull request #1432 from Yangqing/dev
fix relu cudnn test bug
Merge pull request #1417 from Yangqing/dev
relax benchmark milliseconds threshold
clean incorrect relu test code
Prevent Matlab on OS X from crashing on error
documentation bug
Merge pull request #1344 from baeuml/minor-whitespace-in-logging-message-fix
Minor whitespace fix in logging message in HDF5 output layer
make release, debug build dirs configurable in Makefile
groom ignore
Forward declare boost::thread instead of including boost/thread.hpp in internal_thread.hpp.
Update data_transformer.hpp
[docs] re-title docs, count forks
[docs] BVLC Caffe acknowledgements
[docs] cite the arXiv paper
Merge pull request #1332 from tleyden/master
Merge pull request #1326 from jackculpepper/absgradatzero
Fix build error caused by pthread lib order
Fixed a memory leak issue in InternalThread (and removed caffe::Thread calss).
include opencv only in .cpp
define gradient at zero to be zero
Merge pull request #1319 from kmatzen/lmdb_iter_fix
Merge pull request #1320 from sguada/remove_TIMING
Remove TIMING from ForwardBackward
LMDB doesn't support many concurrent read-only transactions, so this preallocates one read-only transaction and reuses it.  It's very important that iterations are considered invalid after a commit has been performed.
back-merge
Merge pull request #1315 from sergeyk/master
Fixing finetune_flickr_style model reported accuracy.
Merge pull request #1308 from sguada/new_lr_policies
Merge pull request #1309 from CellScope/edit-brew-boost-python
Edit boost-python formula
Fix init current_step
Merge pull request #1296 from crizCraig/patch-5
Merge pull request #1293 from sguada/new_lr_policies
Sometimes anaconda is installed in root.
Adapt lenet_multistep_solver.prototxt to current solvers
Merge pull request #190 from sguada/new_lr_policies
Merge pull request #1239 from sguada/encoded
Added CPUTimer Make timing more precise using double and microseconds
Upgrade compute_image_mean to use gflags, accept list_of_images, and print mean_values
Change caffe time to do forward/backward and accumulate time per layer
Added cache_images to WindowDataLayer Added root_folder to WindowDataLayer to locate images
Speed up WindowDataLayer and add mean_values
Add root_folder to ImageDataLayer
Add fast code for transform(cv::Mat,Blob)
Added timers for benchmarking
Added test for encoded Datum to test_io.cpp
Added encoded datum to io
Added encoded option and check_size to convert_imageset
Merge pull request #1288 from sguada/first_last
Added first_key and last_key to dataset
Merge pull request #1238 from kmatzen/db
[docs] proofreading suggested by @cNikolaou
Merge pull request #1283 from jeffdonahue/optional-pkg-config
Reintroduce pkg-config with optional Makefile.config flag.
Reworked the Coder interface such that a Dataset now has both user-definable KCoder and VCoder which default to a set of DefaultCoder's based on types K and V.  Reworked the DefaultCoder's such that if none are available, a static assertion fails with a relevant message.
Had forgotten to set some of the Dataset test cases to LMDB backend.
Renamed Database interface to Dataset.
Templated the key and value types for the Database interface.  The Database is now responsible for serialization.  Refactored the tests so that they reuse the same code for each value type and backend configuration.
Switched some Database logging statements from LOG to DLOG.
Added function to Database interface to retrieve keys.  Exposed a bug with LMDB iterators.  Fix the bug and updated how invalid iterators are represented.
Changed Database::buffer_t to Database::key_type and Database::value_type
The LevelDB iterator/DB deallocation order bug is pretty much fixed by having each iterator hold a shared pointer to the DB.  I manually specified a deconstructor for the LeveldbState to make it clear what order these two things need to be deallocated in.
Updated Database interface to take key and value by const reference for put and key by const reference for put.  Additional copies are made for get and put in the LMDB implementation.
Updated Database interface so that rather than CHECKing for certain conditions inside open, put, get, and commit, these functions return a bool indicating whether or not the operation was successful or a failure.  This means the caller is now responsible for error checking.
Added some tests for the Database iterator interface.  Updated the post-increment operator so that it forks off a copy of the LevelDB or LMDB iterator/cursor when necessary.  Neither of these APIs allow you to directly copy an iterator or cursor, so I create a new iterator and seek to the key that the previous one was currently on.  This means the pre-increment operator can be much cheaper than the post-increment operator.
Added get interface to Database.  Added test cases for Database.  Fixed a few bugs related to ReadOnly mode in Database in order to pass test cases.
Added a couple of sanity checks to make sure the datum buffer sizes matched what we expected.
Updated Database interface to use custom KV type rather than std::pair.  Removed two buffer copies in dereference operation for DB iterators.
Updated extract_features to take a leveldb/lmdb config option.
Switched create_cifar10.sh output from leveldb to lmdb.
Updated cifar10 build script to specify db backend.
data layer test was relying on the autocommit on close db behavior that was recently removed.
Don't autocommit on close for the databases.  If they were read-only, then they might fail.
Updated interface to make fewer string copies.
Some cleanup to make travis happy.
Refactored leveldb and lmdb code.
Merge pull request #1277 from Yangqing/dev
some namespace cleaning.
Revert "OpenCV should be compiled using pkg-config options." -- breaks compilation on working systems
[examples] fix reference model name for flickr fine-tuning
Merge pull request #1270 from Yangqing/dev
move registration code to corresponding cpp files.
Merge pull request #1269 from Yangqing/dev
some namespace simplification
Merge pull request #1264 from Yangqing/dev
fix flaky math functions, remove unnecessary instantiations.
fix flaky test EXPECT_EQ code, using EXPECT_FLOAT_NEAR per Jeff
Merge pull request #1261 from kmatzen/minor_changes
Fixed CMakeList to work with OpenCV 3.
Added version dependent test for IMREAD_COLOR.
OpenCV should be compiled using pkg-config options.
Minor fixes.  (1) cudnn.hpp uses CHECK_EQ internally, so it needs to include glog at some point.  Including caffe/common.hpp.  (2) I often misconfigure some layer and softmax breaks when the dimensionality is too small for the input layers.  Check and fail fast.  (3) CV_LOAD_IMAGE_COLOR is deprecated and has been removed in OpenCV 3.0.  Replaced with cv::IMREAD_COLOR.
[docs] pip install harder
[docs] pip install packages in order for dependencies
Merge pull request #1258 from Yangqing/instantiation
adding missing libraries - lm and lstdc++
Added Multistep, Poly and Sigmoid learning rate decay policies
fix instantiation
Merge pull request #1195 from longjon/python-copy-from
[docs] note boost 1.56 an CUDA conflict on OS X
[docs] update homebrew instructions for boost and boost-python split
[example] re-title LeNet / MNIST heading too
[example] add LeNet to MNIST title, fix paths to be from root
[example] fix data script paths for flickr fine-tuning
Merge pull request #1206 from BlGene/dev
Fix CMake build of pycaffe - generate right shared library name - fix CMake linking with the new layer factory - find numpy
Merge pull request #1227 from longjon/crash-backtrace
Merge pull request #1226 from longjon/check-solver-prototxt
Merge pull request #1232 from baeuml/cmake-move-dependency-discovery
[cmake] move dependency finding to root CMakeLists.txt
correct naming in comment and message about average_loss
SliceLayer: fix whitespace
use glog to provide a backtrace on crash
[fix] check solver prototxt parsing
Merge pull request #1223 from baeuml/fix_pthread_link_cmake
Merge pull request #1179 from ducha-aiki/fix_pthread_link
change linking order such that pthread comes in the back
change -lpthread to -pthread in linking
Merge pull request #1221 from sguada/fix_cuddn_pooling
Missing param.pad condition for CUDNN pooling
Merge pull request #1070 from sguada/move_data_mean
uin8 spell check
bundle pixel mean into CaffeNet as comments
Fixed crop error and add test_data_transformer
Fix calls to Rand() and test_data_layer error
Fix OSX compilation for nvcc with opencv
Added mean_value to specify mean channel substraction Added example of use to models/bvlc_reference_caffenet/train_val_mean_value.prototxt
Added more tests to test_io for CVMatToDatum
Add ReadImageToDatumReference to test_io
Merge pull request #1214 from sguada/global_pooling
[fix] include Python.h instead of re-ordering for pycaffe build on OS X
[fix] bend pycaffe to the whims of OS X header order
Merge pull request #1215 from shelhamer/clang-whole-archive
[fix] set cmake static link command for clang++ and g++ globally
[fix] translate g++ whole archive to force load for clang++ compilation
Added global_pooling to set the kernel size equal to the bottom size
Add CVMatToDatum
Added test_io and faster cv::Mat processing
Add flag check_size=false to convert_imageset
Refactor common code
Update description data_transformer.hpp
Remove Datum from WindowDataLayer
Initial cv::Mat transformation
Fixed MemoryDataLayer to make it work with pycaffe
Move data_mean into data_transformer remove datum_* from BaseData
Merge pull request #1204 from jeffdonahue/exp-layer
save/restore shared weights unit test
[fix] comment typo
Add ExpLayer to calculate y = base ^ (scale * x + shift)
Add caffe_gpu_exp math function
Merge pull request #1208 from Yangqing/dev
[pycaffe] expose Net::SharedTrainedLayersWith as Net.share_with
Merge pull request #1196 from longjon/python-solver-improvements
[pycaffe] expose Net::CopyTrainedLayersFrom as Net.copy_from
add factory header to caffe hpp
Back-merge to include #1198
Merge pull request #1198 from dbbert/patch-1
Update detect.py
[fix] lint causing travis failures
Merge pull request #951 from gcinbis/patch-1
caffe.proto: do some minor cleanup (fix comments, alphabetization)
Back-merge branch 'master' into dev (for fix in PR #1203)
Merge pull request #1203 from jeffdonahue/fix-output-blob-indexing
[fix] solver indexing of output blobs was incorrect for non-singleton outputs
Merge pull request #1096 from qipeng/smoothed-cost
[pycaffe] expose SGDSolver.iter
add accessor for Solver::iter_
[pycaffe] expose SGDSolver.test_nets
[pycaffe] add converter for vectors of Nets
[pycaffe] fix comment typo
[fix] check and load weight for backward w.r.t. data
remove a wrong space in common.hpp
fix cuDNN build by readding line deleted in #1167
Merge pull request #1191 from jeffdonahue/hdf5data-cleanup
hdf5_load_nd_dataset_helper: check that dataset exists first
HDF5DataLayer: die on failure to open source file
Die on failure to load HDF5 data file.
Cleanup HDF5DataLayer log messages.
hdf5_data_layer.cpp: fix indentation
Merge pull request #1183 from pluskid/hdf5layer
added test case to cover new HDF5 behavior
make HDF5 layer support multiple data output
test_gradient_based_solver.cpp: removed unused typedefs
Merge pull request #1167 from Yangqing/factory
doxygen
Merge pull request #1187 from longjon/fix-cudnn-pooling-tests
cuDNN pooling layer tests know that nonzero padding is not supported
use method overrides for CuDNNPoolingLayer top blob checking
Merge pull request #1186 from ashafaei/error-fixes
Fixed some errors in layer_factory and cudnn_pooling
Merge remote-tracking branch 'bvlc/master' into dev
Merge pull request #1166 from pluskid/master
Changed linking order: -pthread -> back. Otherwise error: /usr/bin/ld: /usr/local/lib/libgflags.a(gflags.cc.o): undefined reference to symbol 'pthread_rwlock_wrlock@@GLIBC_2.2.5' /lib/x86_64-linux-gnu/libpthread.so.0: error adding symbols: DSO missing from command line collect2: error: ld returned 1 exit status
[examples] adding class names and deploy version of Flickr Style net
static initialization order fiasco
add explicit declaration - does that help the flakyness?
add long-ignored threshold layer
consolidate duplicate code
cmake.
Mute factory registration message
Add back static library. Using -Wl,--whole-archive will allow us to preserve all symbols.
Pre-lunch fun: add a dynamic library guard test.
more docs
running factory.
Merge pull request #1172 from Yangqing/conv_factory
message
Merge pull request #1161 from jjkjkj/dev-threshold-fix
const fix
cudnn pooling fallback option
fix hdf5 data layer bug
update HDF5 layer test data.
tweak test case to expose bug.
Update layer_factory.cpp
Merge pull request #1149 from ashafaei/crop_bugfix
Merge pull request #1157 from ducha-aiki/fix-extract-features
Random crop bugfix and abstracting random number generation inside data_transformer
Removed unnecessary "mutable"
Merge pull request #1147 from savy-91/patch-1
Merge pull request #1138 from ksimonyan/vgg_models_support
Back-merge
Merge pull request #1152 from sguada/fix_cv_size_order
Fixed param order of cv::Size in cv::resize
added a Matlab demo with mean BGR pixel subtraction instead of the mean image subtraction
Changed "blas" to "openblas"
RGB -> BGR in the matlab demo
added example usage to the Matlab script
added comments to the Matlab demo script
added matcaffe_demo for the VGG models (RGB input)
added support for "k" LRN parameter to upgrade_proto
adds a parameter to the LRN layer (denoted as "k" in  [Krizhevsky et al., NIPS 2012])
web demo fix, closes #1002
Merge pull request #1128 from shelhamer/default-db-lmdb
switch examples to lmdb (except for custom data loaders)
fix cifar10 paths so they can be run from caffe root
default backend to lmdb for image conversion and mean computation
Back-merge
Merge pull request #1126 from shelhamer/window-data-param-upgrade
define up-to-date all-in-one model for pascal finetuning
load transform params in window data layer
include WindowDataLayer in data param upgrade
Merge pull request #1115 from rickardnorlander/master
Merge pull request #1118 from shelhamer/1x1-conv
combine col_{data,diff} into single col_buff to halve memory usage
Back-merge
optimize 1x1 convolution for Network-in-Network style layers
drop out-of-date conv test comments
Merge pull request #1117 from ronghanghu/fix-finetune-example
fix directory in finetune pascal example
Merge pull request #945 from longjon/fixtypes
fix types of (Layer)SetUp, Reshape, Forward, and Backward calls
fix cifar10 paths so they can be run from caffe root
Fix typo in LRN-expression in docs
Merge pull request #1112 from BVLC/next
relax precision of gradient-based solver tests
[example] groom siamese notebook
Merge pull request #959 from nickcarlevaris/contrastive_loss
[docs] order ipython notebooks
[example] resurrect imagenet training scripts
[model zoo] ignore models -- only for reference or zoo
[model zoo] download from gist grooming
Merge pull request #1110 from sergeyk/dev
[model zoo] download gist script
fix warning
Merge pull request #594 from longjon/layer-reshaping
check that LRN's local_size is odd as the current implementation requires
[docs] clarify the use of Blob::Reshape a bit
[pycaffe] expose Net::Reshape
add Net::Reshape for only reshaping
include Reshape in caffe time
test net reshaping
default LayerSetUp to no-op instead of NOT_IMPLEMENTED
call Reshape in Layer::SetUp
split off Reshape for vision layers
split off Reshape for common layers
split off Reshape for neuron layers
split off Reshape for loss layers
split off Reshape for data layers
separate setConvolutionDesc from createConvolutionDesc
separate setTensor4dDesc from createTensor4dDesc
enable reshaping in the forward pass
don't reallocate blobs when shrinking memory use
add abstract Layer::Reshape, and document the new method protocol
use Blob directly instead of shared_ptr for EltwiseLayer::max_idx_
Merge pull request #1104 from shelhamer/conv-comments-tests
Merge pull request #1100 from cNikolaou/issue1099
[docs] lenet grooming
[docs] comment ConvolutionLayer
test convolution by random weights for robustness
test convolution against explicit reference implementation
Updated mnist/readme.md file with additional information.
Update readme.md files of cifar10 and mnist examples. Fixed broken links.
Display averaged loss over the last several iterations
Merge pull request #1093 from CellScope/io-cant-load-error-msg
[Bugfix] Move error checking closer to file read
Merge pull request #1088 from shelhamer/fix-solverstate-filename
Merge pull request #1091 from ronghanghu/fix_window_data_layer
set up datum size for WindowDataLayer
[fix] snapshot model weights as .caffemodel, solver state as .solverstate
[example] update paths in net surgery
Merge pull request #1083 from longjon/fix-solver-gpu-init
fix caffe train GPU initialization
Merge pull request #1077 from bhack/glog_ppa
Merge pull request #1076 from kloudkl/cuda-6.5
Fix a little typo
Fix comments
fix spelling error in caffe.proto
fix out-of-date next ID comment for SolverParameter
Update CUDA to version 6.5 in the Travis install script
Add ppa for gflag and glog
Merge pull request #1051 from jeffdonahue/travis-red-errors
add -fPIC flag to CMake build
restore "red X" build failures in Travis
Merge pull request #1067 from bhack/lmdb
Fix lmbdb travis with openldap
Merge pull request #1053 from jeffdonahue/to3i-elem_max_layer
Added contrastive loss layer, associated tests, and a siamese network example using shared weights and the contrastive loss.
lint & reduce gradient check stepsize to pass checks
Implemented elementwise max layer
Back-merge to dev for slides
Merge pull request #1052 from shelhamer/caffe-presentation
[docs] replace intro slides with caffe tutorial
Revert "call __signbit for CUDA >= 6.5 implementation" -- doesn't compile on OSX w/ CUDA 6.5
Merge pull request #1050 from jeffdonahue/linecount-more
Merge pull request #1044 from jeffdonahue/no-tmpnam
linecount counts more dirs than just src/
[lint] cuDNN conv declaration
Merge pull request #1046 from shelhamer/cudnn
Merge pull request #1049 from niuzhiheng/dev
Fixed CMake script of FindOpenBLAS.
Merge pull request #1045 from akosiorek/origin/dev
Merge pull request #1048 from jyegerlehner/conv_layer-init-weight
Fix more lint.
Repair crash in conv_layer due to weight pointer being NULL.
[docs] include cuDNN in installation and performance reference
report cuDNN error string
CUDNN_CHECK
strategize cuDNN softmax
strategize cuDNN activations: ReLU, Sigmoid, TanH
strategize cuDNN pooling
strategize cuDNN convolution
call __signbit for CUDA >= 6.5 implementation
add cuDNN to build
added common.cpp explicitly to tests
cpp and cu files processed separately in test build
enabled object file reusing in test builds
add <cuda>/lib64 only if exists to suppress linker warnings
remove uses of tmpnam
fix transform_param in mnist_autoencoder.prototxt
[docs] tutorial/layers: fix inner product sample
[docs] tutorial/layers: describe some more data layers
[docs] tutorial/layers: clean up sample markdown
[docs] tutorial/layers: brief descriptions of some loss layers
[docs] in tutorial/layers, Options -> Parameters
[docs] split layer params in required/optional
[docs] add LRN layer to tutorial/layers
[docs] fix pooling markdown and add some comments in tutorial
[doc] minor edits to convolution layer in tutorial
[docs] fixup the MathJax notation in tutorial/layers
Merge pull request #1022 from shelhamer/engine
revert separate strategies: engines will extend the caffe standards
revert engine switch for build to always include caffe engine
default engine to Caffe in case config is missing
default engine to Caffe according to compile flag
grooming: drop pointless overrides, stub layer comments
strategize softmax
strategize relu, sigmoid, tanh
strategize pooling
strategize Caffe convolution
ifdef engine default
add engine parameter for multiple computational strategies
groom proto: sort layer type parameters, put loss_weight after basics
shift CUDA code out of common
Added initial Hinge Loss
more layers
conv and pooling
neuron layers doc
update net
fix leaky relu
more blob details
relu,sigmoid,tanh
[docs] fix br code
[docs] link tutorial
[docs] add titles
Merge pull request #1036 from longjon/test-initialization-param
Merge pull request #1039 from sergeyk/dev
Merge pull request #1040 from qipeng/solver-test-fix
Gradient-based solver test fix
added a two-layer network that gets higher accuracy
[docs] fix formatting and other errors in loss & solver
[fix] stop cloc complaint about cu type
fix fine-tuning example: paths, test acc., and total fine-tuning time
HDF5 classification example
Merge pull request #917 from sergeyk/model_zoo
[example] update ImageNet timing for K40
fix model download advice and prototxt name for fine-tuning
Merge pull request #624 from jeffdonahue/squash-layer
add SILENCE layer -- takes one or more inputs and produces no output
add test_initialization option to allow skipping initial test
script to upload/update model info as gist
flickr style fine-tuning model (separated from example read me)
minor fixes to docs
removed mention of getting_pretrained_models page and old paths
updating feature extraction example
Renaming CaffeNet model prototxts and unignoring models/*
removing unneeded scripts from imagenet example
proofread model zoo
snapshot model with caffemodel extension
[models] adding zoo readme; caffenet, alexnet, and rcnn models in zoo format
Merge pull request #1034 from sergeyk/dev
[docs] default setting for layout
Merge pull request #1033 from qipeng/dev
[example] convert mnist name fix (crashes xcode compiler)
[example] drop stale mentions of glog env var
Merge pull request #1031 from CellScope/mnist-tutorial-update
Inline latest lenet_solver.prototxt
Correct reference to lenet_train_test.prototxt
Point to local file, not github file
Update paths
Merge pull request #955 from kloudkl/data-layers
[example] upgrade fine-tuning example to new transformation param
Merge pull request #973 from shelhamer/tutorial-docs
[docs] configure doxygen + docs script for docs/doxygen site output
update doxygen config to stop warnings
[docs] suggest the CVPR14 deep learning tutorial for nice contrast
[docs] draft data
wrap up solver.md -- add update info for all solvers with citations; rules of thumb for SGD
net.hpp: Doxygen-format docs
solver.hpp: add \briefs
syncedmem.hpp: \brief and todo
blob.hpp: a little Doxygen-style documentation
filler.hpp: add brief filler descriptions
vision_layers.hpp: Doxygen \brief & TODO stubs.
data_layers: Doxygen \brief & TODO stubs.
common_layers.hpp: Doxygen \brief & TODO stubs.
neuron_layers.hpp: Doxygen-style documentation
loss_layers.hpp: Doxygen-style documentation
layer.hpp: Doxygen-style documentation
.Doxyfile: don't warn if undocumented (maybe someday...)
.Doxyfile: modify to generate C++ docs, excluding tests
.gitignore doxygen-generated documentation
add "make {docs,doxygen}" targets to build doxygen-generated docs
add .Doxyfile: the default Doxygen config file from `doxygen -g`
[wip] vision layers, start convolution
use kramdown for markdown syntax; add mathjax
[docs] add note on Caffe convolution
[docs] draft tutorial subjects
[docs] skeleton documentation subjects
Initialize the transformer rng in the base data layer
Correct the datum size checking conditions of the data layers
Add and transform Datum vector in the MemeoryDataLayer
Place InternalThreadEntry lower in the {,Image,Window}DataLayer.cpp
Add leveldb header back to util/io.cpp
Remove OpenCV stuffs from the memory data layer and io utils
Add lint rule for caffe data layer setup
Fix conflict between nvcc and boost for cmake
Move the rest duplicate codes of the data layers into their base class
Test adding images w/o resizing to the memory data layer
Move transform param one level up in the proto to reduce redundancy
Remove pthread which has been replaced with boost thread
Add transformer to the memory data layer
Implement Forward_gpu in the base prefetching data layer
The BasePrefetchingDataLayer shouldn't join the thread
Simplify the WindowDataLayer using the base class
Remove duplicate codes from the ImageDataLayer
Extract common data layer functionalities out of the DataLayer
Create base data layer and base prefetching data layer
Merge pull request #1025 from mohomran/minor_fix_to_mnist_solver_prototxt
fixed relative path and prefix for adagrad-optimised autoencoder snapshots
Merge pull request #1023 from longjon/unbreak-pycaffe
[pycaffe] use _blob_names, _layer_names instead of removed .name
[pycaffe] expose Net.blob_names and Net.layer_names
[pycaffe] add converter for vector<string> used by _*_names
add CUDA 6.5 error CUBLAS_STATUS_LICENSE_ERROR to cublasGetErrorString enum
revert tools/train_net.cpp to previous, depecated version
Merge branch 'qipeng-solvers' into dev
make MNIST autoencoder solvers start from base_lr 0.01 and step (much better performance) and terminate at iter 65K
make adagrad/nesterov train scripts follow new "run-from-root" convention
Add "test-on-train" stage to test accuracy on the training data; correct test_iter (should be 100 instead of 50)
mnist_autoencoder: always compute both cross-entropy loss and L2 (euclidean) error
hot fix for warning
lint
Re-added solver switch into the new caffe main excutable; fixed AdaGrad MNIST example
lint
Added sanity check for AdaGradSolver; added MNIST examples for solvers
Merge Test{SGD,AdaGrad,Nesterov}Solver; they become subclasses of TestGradientBasedSolver
cleanup caffe.proto
added unit test for solvers and fixed solver bugs
proto conflit, lint, and math_functions (compiler complaint)
fixes after rebase
Addressed Yangqing's comments
fixed caffe.proto after a mistaken rebase
Added L1 regularization support for the weights
bugfixes for AdaGrad
improved numerical stability for AdaGrad
fixed solver constructor in train_net.cpp
converted pointers to shared_ptr
restored vituals in solver.hpp
Solver switching support & implementation of Nesterov's accelerated gradient and AdaGrad
use LMDB in mnist autoencoder examples
make no GPU error in CPU-only mode a little clearer
include comment on CPU mode fine-tuning for Flickr example
Merge pull request #1014 from longjon/cleaner-pycaffe
Merge pull request #1008 from mohomran/mnist_with_lmdb
Merge pull request #1015 from mohomran/fixing_parse_log_script
parse_log.sh adapted to new training log format + fixed typos and updated description
updated lenet_train_test.prototxt + minor correction to create_mnist.sh
minor changes to variable names and error messages + set default backed in convert_mnist_data.cpp to lmdb
data now written to backend in batches
mnist demo now works with lmdb and leveldb (set parameter in create_mnist.sh), switched around includes
[pycaffe] expose Blob.Reshape
[pycaffe] remove name property from PyBlob and PyLayer
[pycaffe] declare the _caffe module init function
[pycaffe] split _caffe into source and header files
[pycaffe] make PyBlob a template over Dtype
[pycaffe] make PyNet a class, not a struct
[pycaffe] use a namespace alias instead of using directives for boost::python
[pycaffe] live in caffe namespace instead of opening it
[pycaffe] use class names of the form Py* instead of Caffe*
remove residual pthread references, but restore in build for gtest
ignore leveldb extension: ldb
Merge pull request #1004 from kloudkl/ignore
fix up leveldb ignore
Merge pull request #1010 from qipeng/boost-thread-with-nvcc
Makefile: fix boost::thread linking, drop pthread, sort
fix up renaming
renaming && typo fix
Merge pull request #1012 from shelhamer/pr-policy
[docs] new PR policy: send master fixes + docs to master
fix data_transformer param_name
Merge pull request #1011 from YS-L/dev
xcode compiler complaints (warnings)...
patch MacOS NVCC boost::thread issue
Fix norm_region param in cifar10 deployment net
back-merge
Merge pull request #997 from ozancaglayn/dev
[docs] Several documentation fixes
Merge pull request #1001 from drdan14/homebrew-git-repair
Explain how to fix homebrew to allow updates after editing formulae
Ignore LevelDB files
Merge pull request #970 from sergeyk/dev
[example] edit fine-tuning and train on ~2000 images, 1557 / 382 split
[example] finetuning CaffeNet on Flickr Style data
Merge pull request #1003 from shelhamer/examples-from-root
set examples paths relative to root
ignore caffe generated files and stop ignoring examples
Merge pull request #1000 from kloudkl/boost-thread
Back-merge to dev for doc fixes + cherry-picks
The return value of WaitForInternalThreadToExit has reversed
Add boost thread in the travis install script
Replace pthread with boost::thread
[docs] Update installation docs to include Fedora
clarify project origin
Merge pull request #857 from netheril96/gflags
create_imagenet.sh updated to new syntax
Merge pull request #993 from Yangqing/sweep
fix layer_factory.cpp bug: there should be no ifdefs
Merge pull request #977 from ozancaglayan/patch-1
Merge pull request #984 from shelhamer/drop-curand-reset
default ilsvrc solving to GPU
default ilsvrc solving to GPU
FIX drop obsolete CURAND reset for CUDA 6.5 compatibility
clarify project origin
FIX web_demo upload was not processing grayscale correctly
FIX web_demo upload was not processing grayscale correctly
Merge pull request #981 from jeffdonahue/fix-eltwise-product
remove warning about LRN layers in CPU mode
Add "stable_prod_grad" option (on by default) to ELTWISE layer to compute the eltwise product gradient using a slower but stabler formula.
Merge pull request #980 from jeffdonahue/fix-memory-used
fix memory_used_ by computing after SetUp
Merge pull request #979 from jeffdonahue/caffe-test-output
'caffe test' prints all scores and their names
fix bug for resizing images.
Merge pull request #976 from alfredtofu/dev
[docs] Update installation docs to include Fedora
fix bug for resizing images.
[example] add fully-convolutional efficiency note + confidence map
[example] add fully-convolutional efficiency note + confidence map
fix internal thread interface confusion
move {InnerProduct,Eltwise}Layer to common instead of vision
fix parameter for transformation in ImageDataLayer constructor
Merge pull request #963 from shelhamer/fix-transform-param
upgrade model definitions for transformation params
upgrade net parameter data transformation fields automagically
compact net parameter upgrade
restore old data transformation parameters for compatibility
Merge pull request #954 from geenux/dev-redundant-data
If specified, --gpu flag overrides SolverParameter solver_mode.
Merge pull request #961 from jeffdonahue/gpu-flag-overrides-solver-mode
Updated installation docs for OS X 10.9 brew install protobuf as well
Updated documentation to include instructions to install protobuf with Python support on Mac OS X
[docs] fix citation bibtex
If specified, --gpu flag overrides SolverParameter solver_mode.
Merge pull request #942 from yosinski/doc-update
Merge pull request #956 from longjon/clean-signbit
Refactor ImageDataLayer to use DataTransformer
specialize cpu_strided_dot before instantiation to fix clang++ build
clean up cpu signbit definition
Refactor DataLayer using a new DataTransformer
Lock the mex file to avoid Matlab crashes.
Merge pull request #940 from ronghanghu/channel-softmax
implement GPU version of Softmax
test softmax and softmax with loss across channels
softmax and softmax loss layers work across channels
add caffe_cpu_strided_dot for strided dot products
milliseconds is a word
Merge pull request #943 from jeffdonahue/parallel-travis-builds
Travis build matrix to do parallel builds for make and CMake; CUDA-less and CUDA-ful.  Move bits of functionality into scripts under scripts/travis for readability. Only generate CUDA compute_50 for perfomance.
Merge pull request #623 from BVLC/cmake
restore .testbin extension, and move caffe_tool back to "caffe". (Required as I had to change the tool target names to '.bin' but give them an OUTPUT_NAME, but the .bin made the test_net tool collide with the test_net unit test.)
use all caps for global preprocess vars (e.g. EXAMPLES_SOURCE_DIR), and other minor cleanup
.travis.yml and .gitignore: various minor cleanup
[docs] CMake build steps and Ubuntu 12.04 install instructions
Reduce packages
Add ppa for CMake for fix 32bit precompiled cmake on 64bit
added gflags + bugfixes + rebase on bvlc/caffe * added gflags requirement in CMake * fixed a bug that linked some tests into caffe lib * renamed tools/caffe due to conflicting target names with caffe lib * rebased onto bvlc/caffe
Added lint target
added proper 'runtest' target
Examples_SOURCE_DIR cmake variable bugfix * it was set only when BUILD_EXAMPLES==OFF
enable both GPU and CPU builds + testing in travis
cpu only build works
cpu only
restoring travis.yml
cmake from binaries
cmake build configuration for travis-ci
fixed lint issues
fixed CMake dependant header file generation
examples CMake lists
cmake build system
Updated installation docs for OS X 10.9 brew install protobuf as well
Updated documentation to include instructions to install protobuf with Python support on Mac OS X
Merge pull request #936 from jeffdonahue/not-stage
Add "not_stage" to NetStateRule to exclude NetStates with certain stages.
[example] set phase test for fully-convolutional model
[example] set phase test for fully-convolutional model
[example] include imports in net surgery
[example] include imports in net surgery
Merge pull request #897 from ashafaei/eltwise-abs
Added absolute value layer, useful for implementation of siamese networks! This commit also replaces the default caffe_fabs with MKL/non-MKL implementation of Abs.
Tried to clarify function of `include' lines and train vs. test network differences
Updated ImageNet Tutorial to reflect new merged train+val prototxt format. Also corrected 4,500,000 iterations  -> 450,000 iterations.
Merge pull request #923 from yosinski/doc-update
Tried to clarify function of `include' lines and train vs. test network differences
Updated ImageNet Tutorial to reflect new merged train+val prototxt format. Also corrected 4,500,000 iterations  -> 450,000 iterations.
Fix from loss-generalization: accidentally removed mid-Forward return from PowerLayer (caused bad performance for trivial PowerLayer cases...)
Merge pull request #686 from jeffdonahue/loss-generalization
Store loss coefficients in layer; use for prettier training output.
Add ACCURACY layer and softmax_error output to lenet_consolidated_solver example.
Also display outputs in the train net.  (Otherwise, why have them?)
Disallow in-place computation in SPLIT layer -- has strange effects in backward pass when input into a loss.
AccuracyLayer only dies when necessary.
Net::Init can determine that layers don't need backward if they are not used to compute the loss.
Make multiple losses work by inserting split layers and add some tests for it. Test that we can call backward with an ACCURACY layer.  This currently fails, but should be possible now that we explicitly associate a loss weight with each top blob.
Generalize loss by allowing any top blob to be used as a loss in which its elements are summed with a scalar coefficient.
Add net tests for loss_weight.
Add loss_weight to proto, specifying coefficients for each top blob in the objective function.
[docs] update docs generation for notebook metadata
[docs] update docs generation for notebook metadata
[example] change notebook name metadata to avoid conflict
[example] fix plt commands in detection
use plt namespace for imshow in filter_visualization.ipynb
Merge pull request #921 from shelhamer/notebook-update
[example] change notebook name metadata to avoid conflict
[example] fix plt commands in detection
use plt namespace for imshow in filter_visualization.ipynb
Fixed the GPU implementation of EuclideanLoss to report the loss to the top layer
Merge pull request #914 from ashafaei/euclidean-loss-fix
Fixed the GPU implementation of EuclideanLoss to report the loss to the top layer
Merge pull request #846 from qipeng/mvn-layer
Merge pull request #863 from jeffdonahue/lint-check-caffe-fns
Fix caffe/alt_fn lint errors.
Create caffe_{,gpu_}memset functions to replace {m,cudaM}emset's.
Add caffe/alt_fn rule to lint checks to check for functions (like memset & memcpy) with caffe_* alternatives that should be used instead.
lint targets should depend on the lint script itself
[examples] fix links in feature extraction
[examples] fix links in feature extraction
[docs] ‘maximally accurate’ in the web demo explanation. closes #905
[docs] [fix] closes #899
Merge pull request #910 from sergeyk/dev
[docs] ‘maximally accurate’ in the web demo explanation. closes #905
[docs] [fix] closes #899
[docs] sorting of examples. if doesn’t work for you, update jekyll.
Merge pull request #909 from sergeyk/dev
[docs] sorting of examples. if doesn’t work for you, update jekyll.
lint
minor fix for layer factory
added cross-channel MVN, Mean-only normalization, added to layer factory, moved to common_layers
Merge pull request #904 from Yangqing/sweep
default raw_scale in python scripts to ImageNet model value
addressed Jeff's comment
lint
reduced blas calls
mean-variance normalization layer
Add a leveldb option function in io.hpp/cpp
[docs] fix example links from install guide
fix formatting error in blob.hpp
Use gflags to show help when the arguments not correct
output loss for caffenet and alexnet train/val models
output loss for caffenet and alexnet train/val models
default raw_scale in python scripts to ImageNet model value
Fix the gflags namespace issue
Merge pull request #891 from kloudkl/gflags_namespace
Merge pull request #892 from kloudkl/distribute_generated_proto_headers
Distribute the generated proto header files
Fix the gflags namespace issue
Merge pull request #888 from ronghanghu/matcaffe-add-check
add necessary input checks for matcaffe
[example] fix example names
[example] fix example names
Merge pull request #880 from BVLC/next
[docs] fix find complaint in example gathering script
[example] fix broken links in ImageNet recipe
Back-merge documentation and fixes
Merge pull request #872 from shelhamer/caffe-tool
consolidate gpu and device_id args in caffe tool
update cli usage in examples
fix deprecation warnings
consolidate test into caffe cli
comment caffe cli
check required caffe cli args
rename caffe cli args and revise text
give usage message for caffe cli
output INFO from caffe cli to stderr by default
consolidaet GPU flag for caffe cli
rename tools
Painless binary mean conversion to matlab matrices.
Merge pull request #868 from shelhamer/license-copyright
lint for copyright
[docs] detail attribution, license, and copyright for development
LICENSE governs the whole project so strip file headers
clarify the license and copyright terms of the project
Merge pull request #816 from shelhamer/pycaffe-labels-grayscale-attrs-examples
drop np.asarray() in favor of declaration (~1.75x speedup)
fix pycaffe context cropping with or without mean
take array in pycaffe `Net.set_mean()` instead of file path
fix pycaffe input processing
Reordering of header includes for convert_imageset.cpp
Fix lint errors
Handles gflags's change of namespace
convert_imageset now uses gflags; optional arguments can be positioned arbitrarily now
[example] include prediction in classification, time on GTX 770
[example] fix example outputs
[example] add caffe to pythonpath in all examples
define caffe.Net input preprocessing members by boost::python
Merge pull request #856 from jeffdonahue/lint-tweaks
Merge pull request #859 from beam2d/fix-cifar-lrn-region
Fix conflict on setting of LRN layers between train/test net and deploy net
Fix header alphabetization lint errors.
Enable the 'build/include_alpha' rules to make lint check that the includes are correctly alphabetized.
Add "lintclean" target to remove current lint outputs -- forces lint to be run again next time "make lint" is run.
Changed path in description to point to parse_log.sh
Merge pull request #855 from jeffdonahue/sgd-solver-test
Add (momentum) SGD solver tests to check that learning rate, weight decay, and momentum are implemented properly on a least squares problem.
Add 'snapshot_after_train' to SolverParameter to override the final snapshot.
modified test_concat_layer.cpp
Merge pull request #848 from netheril96/random
Fix and improve multiple places about random number generation and shuffling
Merge pull request #834 from qipeng/dev
Merge pull request #840 from jeffdonahue/fix-net-speedtest
Fix speedtest (and possibly other tools) by setting the net phase to the current Caffe::phase() unless explicitly specified in the state.
Add tests for phase filtering according to Caffe singleton phase (currently failing as FilterNet ignores the singleton phase).
Add script to speedtest imagenet (currently broken as FilterNet ignores Caffe::phase()).
Merge pull request #839 from jeffdonahue/test-dropout-ratio
Test that DropoutLayer obeys dropout_ratio.
fix compiler complaint in matcaffe
fixed unnecessary conversions in test_solver, and rearraged common.hpp a bit
lint
the compiler complains about solver tests using pointers as bool
turns out you need using::isnan too
Included cmath in common.hpp to avoid isnan complaints from the xcode compiler
[example] fix imagenet classification typo
Merge pull request #825 from shelhamer/mailing-list
[example] include image dimensions for oversampling
[docs] announce caffe-users
[example] standardize imagenet leveldb names
[fix] adding requirements.txt for web_demo. Closes #704
[docs] contact us on webpage
link OpenBLAS as blas
[docs] install update: dependencies, CPU-only, Ubuntu 14.04
Merge pull request #823 from jeffdonahue/hdf5output-gpu-fix
Also apply HDF5OutputLayer fix to GPU version.
Set correct solver_mode in SolverTest so Travis build doesn't randomly fail.
fix some namespace with std::signbit
Merge pull request #710 from geenux/dev
Merge pull request #734 from jeffdonahue/all-in-one-net
Use unified train/test nets in examples.
Incorporate NetState{,Rule} into Solver/Net.  Net::FilterNet includes/excludes layers based on whether the NetState meets each layer's NetStateRule(s).
Add unit tests and skeleton code for Net/Solver filtering functionality.
Add NetState message with phase, level, stage; NetStateRule message with filtering rules for Layers.
[example] standardize imagenet leveldb names
Merge pull request #820 from geenux/dev-fixmake
Fix choice MKL directory from Makefile.config
Merge pull request #505 from shelhamer/non-square-filters
test non-square filters by separable convolution of Sobel operator
fix GPU indexing
test rectangular im2col
im2col + convolve non-square filters, padding, and stride
add h/w kernel size, stride, and pad for non-square filtering
[docs] compile gflags with -fPIC for linking
[docs] install glog first given incompatibility
[docs] fix missing glog install cd
Merge pull request #813 from sergeyk/dev
make "all" the default target
FIX: updating HDF5 input test for new test data
FIX: both data and label now copied correctly in HDF5 output layer
FIX: tests now catch bug reported in #750 (in HDF5 output layer)
Merge pull request #812 from Yangqing/sweep
lint
Merge pull request #733 from longjon/pycaffe-tweaks
fixing comment
gflags 2.1 bugfix (or rather a hack).
Merge pull request #805 from alfredtofu/dev
Merge pull request #807 from qipeng/dev
set_mode to CPU in ArgMaxLayerTest constructor to avoid random Travis failures.
Merge pull request #806 from jeffdonahue/travis-minimal-cuda
Only install the minimal CUDA subpackages necessary for building.
Update image_data_layer.cpp
relaxed timer test requirements
Merge pull request #802 from jeffdonahue/caffe-bin-symlink
Symlink to tool bins without the .bin extension
Merge pull request #800 from jeffdonahue/zero-indexed-train-iter
Move loss display before lr display in ComputeUpdateValue.
Make training iterations 0-indexed.
Fix my nonsensical variable names.
Merge pull request #796 from jeffdonahue/solver-debug-info
Print just the mean absolute value (no sum/l1norm)
Print blob L1 norms during forward/backward passes and updates if new "debug_info" field in SolverParameter is set.
Merge pull request #789 from Yangqing/sweep
LOG(ERROR)->LOG(FATAL), and misc script changes.
Merge pull request #793 from jeffdonahue/infogain-test
using caffe::string to be consistent with other string definition.
Add gradient checks for infogain loss layer, letting it take the infogain matrix as the third bottom blob.
oops, wrong deprecation message (should have --)
lint
Adding new caffe binary that does everything in one binary; deprecating device_query, finetune_net, net_speed_benchmark, train_net
include benchmark.hpp
Merge pull request #776 from Yangqing/sweep
travis: gflags still needs -fPIC, otherwise it makes caffe cry.
I am really bad at debugging travis.
turns out that glog does not compile with gflags 2.1 - compiling glog first and then gflags.
travis - does adding cflags help? want to keep minimal invasion into gflags installation.
travis
Cleanup pthread code for data layers
gflags should preferrably be installed before glog
add gflags dependency doc
add gflags dependency to caffe.
Merge pull request #773 from qipeng/lrelu
numerical stability improvement
Merge pull request #766 from rbgirshick/matcaffe-cxx
Use the same CXX for matcaffe as for the rest of the build
Merge pull request #762 from rbgirshick/upgrade-pad-pooling-layers
Merge pull request #760 from bhack/fix_loopcopy
Correctly apply padding to pooling layers when upgrading from V0
Fix repeated field copy loop
Merge pull request #755 from jeffdonahue/bhack-split_dim
SliceLayer: post-rebase fixes, cleanup, etc. (some from changes suggested by @sguada).  Test for both num & channels in forward & backward; use GaussianFiller so that tests are non-trivial.
Add split dim layer
Merge pull request #740 from qipeng/lrelu
reduced multiplications & fixed unit test
leaky relu + unit test
Merge pull request #752 from Yangqing/sweep
Merge pull request #742 from longjon/direct-blob-buffers
Merge pull request #743 from longjon/make-everything
Merge pull request #615 from kloudkl/top-k-argmax
remove unused includes in AccuracyLayer and ArgMaxLayer
Merge pull request #518 from longjon/fromto
add an "everything" target to make for comprehensive build testing
use Blob directly instead of shared_ptr for WindowDataLayer buffers
use Blob directly instead of shared_ptr for ImageDataLayer buffers
use Blob directly instead of shared_ptr for DataLayer buffers
use Blob directly instead of shared_ptr for DropoutLayer::rand_vec_
use Blob directly instead of shared_ptr for PoolingLayer::max_idx_
use Blob directly instead of shared_ptr for InnerProductLayer::bias_multiplier_
use Blob directly instead of shared_ptr for ConvolutionLayer::bias_multiplier_
Fix style issues in accuracy & argmax layer
Include <utility> for pair in the accuracy layer
Limit the comparison functions to have file scope
Add more test cases for the accuracy layer
Refactor the accuracy layer with std::partial_sort
Move compararing function from common_layers to argmax_layer
Use std::partial_sort in the ArgMaxLayer as suggested by @shuokay
Simplify the top-k argmax layer using std::sort
Add the test cases for the mulitple top predictions argmax layer
Extend the ArgMaxLayer to output top k results
pycaffe: test channel_order and input_scale against None
pycaffe: reorder exceptions
pycaffe: allow unspecified mean. Fixes #671.
Merge pull request #732 from longjon/travis-pycaffe
Travis builds pycaffe
use /usr instead of /usr/local for default Python include/lib
test consistency of From/To Forward/Backward
comment in net.hpp to explain subtleties of From/To on DAGs
pycaffe: expose Forward/Backward From/To as kwargs start and end
add Net::Forward/Backward From/To
reapply namespace change
Merge pull request #730 from Yangqing/sweep
cosmetics: add syntax = proto2
Merge pull request #718 from Yangqing/dev
lint
Merge pull request #716 from Yangqing/dev
compute_image_mean namespace fix.
continuous integration of master build
Merge pull request #561 from shelhamer/cpu-only-build
check CPU-only everything, CPU + GPU build with travis
relax benchmark test timing for cheap hardware / CI build
switch travis build to CPU-only flag, drop runtestnogpu target
collect CUDA includes and calls, separate from CPU-only mode, leave out
add guards to drop GPU code in CPU-only mode
stub out GPU layer methods to crash loudly in CPU-only mode
configure Makefile for CPU-only build
neuron_layers.hpp should not need to include leveldb
move using statements inside namespace caffe to avoid polluting the whole name space.
[fix] adding requirements.txt for web_demo. Closes #704
Another bugfix related to my CPU/GPU test changes: make NetTest a MultiDeviceTest (Caffe:set_mode(Caffe::CPU/GPU) isn't run without this).
Merge pull request #660 from jeffdonahue/param-propagate-down
Add Net Test to verify correct param_propagate_down behavior.
Use Blobs instead of SyncedMemorys for the bias_multiplier_'s.
Make ConvolutionLayer and InnerProductLayer abide by param_propagate_down_
Add param_propagate_down_ vector to layer, populate according to blobs_lr in Net::Init
use layer_param instead of layers_[layer_id]->layer_param()
Fix Makefile warning error message.
[docs] contact us on webpage
release net surgery example from #455
[example] elaborate net surgery description
define fully-convolutional imagenet model
save from python for net surgery
fix choice of clang++ in OS X build
Merge pull request #698 from jeffdonahue/softmax-layer-test-devices-fix
Fix SoftmaxLayerTest: forgot to change this one to use DtypesAndDevices; was causing Travis build to randomly fail if a previous test had set the mode to GPU (which no test that is run by 'make runtestnogpu' should, so I guess there's another bug somewhere).
Merge pull request #696 from rbgirshick/matlab_2014a_fix
fix bug that breaks MATLAB 2014a compilation
Merge pull request #694 from jeffdonahue/travis-tweaks
Add blank lines between fields for readability.
Replace CUSTOM_CXX env var to specify non-default C++ compiler.
Run Travis build on all branches (remove whitelist from .travis.yml).
Add --keep-going flag to first make so that any targets that can be built are built; write out full -j flag as --jobs for clarity.
fix Makefile comment about library names
Merge pull request #685 from jeffdonahue/seed-hinge-loss-test
Seed HingeLossLayerTest; bad values can cause test (and therefore Travis CI build) to fail
Merge pull request #681 from BVLC/travisci
Travis build failure wasn't working for lint/warn because they didn't exit with a non-zero code -- this fixes that.
@jeffdonahue's tweaks to .travis.yml config: -Add (CPU-only) test, lint, warn and parallel (-j 4) to travis CI build. -Add /usr/local/lib to travis config (seems needed for LMDB). -Put export in "before_script"; disable clang build -- doesn't work on Linux. -Cache Ubuntu apt packages. -Install bc package to hopefully suppress "bc: not found" errors -Get apt packages before_install as suggested by Travis official docs -Remove specified email address and IRC notifications (emails are sent to the committer by default; others can view build results in public Travis feed, on pull requests, etc.).
-Override the default compiler by specifying a CXX in Makefile.config instead of CUSTOM_CXX, as Travis exports CXX as the compiler env variable name. -Change TEST_HDFS -> TEST_HXX_SRCS.
@huyng's .travis.yml integration configuration file to install and test Caffe.
Move test headers to include/. Add a test param to test both CPU and GPU (with both float and double Dtypes).
back-merging [docs] changes and web demo [example] addition; updating net_surgery example to new format
Merge pull request #679 from sergeyk/master
[example] image classification web demo
Merge pull request #675 from sergeyk/master
[docs] shelhamer's minor suggestions
[docs] updated instructions for contributing documentation
[docs] moved example md’s to examples/**/md’s and added script to gather them for publication
[docs] cosmetic
fix link for caffe_rcnn_imagenet_model
Back-merge documentation and fixes
host materials on dl.caffe.berkeleyvision.org
fix caffe acm-mm paper link
Merge pull request #633 from kloudkl/cpu-only-memcpy
Replace cudaMemcpy with caffe_gpu_memcpy in SyncedMemory per @longjon
Implement @Yangqing's solution to copy memory in the SyncedMemory
Switch to GPU mode when pointer is move to or from GPU in SyncedMemory
Check the GPU mode to decide which memcpy to use
Avoid using cudaMemcpy for memcpy when there is no GPU and CUDA driver
makefile hotfix
Merge pull request #661 from jeffdonahue/fix-error-output
fix bug introduced by warning logs: errors didn't print because they are logged to the warnings file
[docs] readme
[docs] got rid of redundant README, updated development instructions
Makefile: cleanup lint/warn report logic (and make the two more consistent)
[docs] reworked index page, got rid of publications page
Merge pull request #649 from jeffdonahue/warnlog
Output a lint report for every source file linted; use to lint incrementally
Dump compiler warnings to *.warnings.txt; use "make warn" to print them
Merge pull request #647 from jeffdonahue/nocleanlinecount
Don't make clean when running linecount
Merge pull request #614 from ronghanghu/rectangular_pooling
added gradient check for non-square pooling
fixed style errors
Merge pull request #611 from shelhamer/makefile-config-cxx
add tests for rectangular pooling regions
fixing pooling SetUp() to allow default values for stride and pad
Update pooling_layer.cu
Update pooling_layer.cpp
Update vision_layers.hpp
Update caffe.proto
point to reference performance from installation, add GTX 770
customize compiler setting in Makefile.config
Merge pull request #549 from jamt9000/fix-resize-crop-pil
Merge pull request #555 from shelhamer/uva-memory
Merge pull request #602 from kloudkl/layers-in-order
fix casts (static for void*)
reduce caffe_copy to instantiations, split off caffe_memcpy for void*
replace all memset with caffe_set() / caffe_gpu_set()
replace all memcpy by caffe_copy
do all caffe_copy() as UVA mem copy, and drop caffe_gpu_copy()
replace softmax cudaMemcpy with caffe_gpu_copy
switch to unified virtual addressing CUDA memcpy
report UVA in platform test
Merge pull request #609 from jeffdonahue/multiconv
ConvolutionLayer can take N bottom blobs and N top blobs
add EqualNumBottomTopBlobs() property for layers; use in ConvolutionLayer
Organize the loss layers in alphabetical order
Arrange the data layers to be in alphabetical order
Separate layers relatively independent of images out of vision_layers
acknowledge BVLC PI Trevor Darrell for advising Caffe
fix uninitialized variable warnings in tools
Update Makefile.config.example
Merge pull request #545 from jamt9000/im2col-kernel-test
lint
Merge pull request #502 from sguada/fix_dropout_backward
Remove Cuda.major >= 2 check on Dropout test
Check that pointers are different before copying in caffe_copy and caffe_gpu_copy
Added test to Dropout to check gradients during Test phase
Fix var names in Dropout.cu
Modify Dropout to allow backward pass in TEST phase
Fix building tests with parallel make
Merge pull request #510 from crizCraig/patch-1
Merge pull request #531 from flickr/dev-top-k-accuracy
Comment-fix.
Update name of last added param.
Add unit test for accuracy layer.
Next LayerParameter proto id
Use vectors instead of arrays.
Compute top-k accuracy in AccuracyLayer.
Incorporate top_k param into AccuracyLayer and check it's value.
Add parameter for AccuracyLayer in proto.
add latest CUDA arch to fix invalid device function errors
Merge pull request #554 from shelhamer/nvcc-arch-50
add latest CUDA arch to fix invalid device function errors
Make resizing & cropping with PIL work
Test for im2col kernel
Merge pull request #511 from kloudkl/extract_multiple_features
Merge pull request #546 from BVLC/weight-sharing
rename layer -> param mapping for clarity
change weight blob field name to param
weight sharing
Merge pull request #497 from jeffdonahue/fix-backward-interface
force_backward works properly with non-backproppable things
change Backward interface: propagate_down is a vector -- use to fix long-standing issue with how this is handled in loss layers (esp. EuclideanLossLayer)
Merge pull request #522 from sguada/accuracy_without_loss
file SoftmaxWithLoss in with loss layers
Merge pull request #488 from longjon/wall-werror
switch language to "related publications"
add publication section to homepage
fix caffe paper link -- still hasn't appeared on arxiv yet
Merge pull request #543 from shelhamer/publications
Merge pull request #539 from sguada/top_5_docs
Added top-1 and top-5 accuracy for the caffe networks to docs
content ourselves to -Wall without -Werror for now
make clang++ happy on OSX by not linking with pthread
fix test data layer post-lmdb
Merge pull request #478 from kloudkl/cpu_only_tests
turn off some warnings for older compilers
add WARNINGS to CXXFLAGS
upgrade warnings to -Wall -Werror -Wno-sign-compare
don't end comments with \, so that -Wcomment can be used
initialize and comment variables that the compiler finds suspicious
move CUDA 6.0 check into switch statement itself
add missing const qualifiers to MemoryDataLayer ExactNum* functions
remove unused variables from tests
remove unused variables
initialize in declared order in tests
initialize in declared order
check if window file is empty in WindowDataLayer
actually check status values from all HDF5 calls
Merge pull request #427 from jamt9000/fix-kernel-index
fix SOFTMAX_LOSS to work with loss top blob interface
add skeleton of the Caffe publications page
Init google logging
Replace the raw pointers with shared_ptr to ensure memory is released
No need to manually delete the pointers which are managed by std::vector
Progress should be reported for each feature blob
Extract multiple features in a single Forward pass
Merge pull request #508 from kloudkl/ImageDataLayer-RNG-core-dump
Merge pull request #529 from crizCraig/patch-3
There are 256 filters in conv2.
Merge pull request #398 from sguada/L2_hinge_loss
explicitly name L1 hinge test
fix whitespace error in HingeLossLayer
Change hinge_norm to norm in test_hinge_loss
Remove C_ mentions, extra spaces and change hinge_norm to norm
Now AccuracyLayer only computes accuracy, one should use LossLayers to compute loss Changed all val.prototxt in examples to add a LossLayer to compute loss in Test
Unify L1 and L2 Hinge_Loss to follow convention
Fix the loss to follow the convention
Fixed switch and test l2hingeloss
Remove spaces and merge tests into one file
Removed L2HingeLoss class now a case within HingeLoss class
Merge HingeLoss and L2HingeLoss by adding hinge_norm to params
Verify the result of memtest in SyncedMemoryTest::TestGPURead
Rename curand_availability_logged according to the Google style guide
Revert the namespace ending comment to the same line of the bracket
Suppress redundant log messages of unavailable curand
Separate TestForward into Test{CPU, GPU}Forward in HDF5OutputLayerTest
Extract GPU code out of SyncedMemoryTest::TestCPUWrite
Initialize the RNG generator with an orthogonally newed Generator
Fix the condition prefetch_needs_rand in the ImageDataLayer
remove erroneous comment in ArgMaxLayer
Merge pull request #521 from sguada/set_device_id_at_init
Modified test_net to check loss layer with top
Now Loss layers would return the loss in the top blob if requested
Set device_id at the begining of Solver.Init() to avoid using memory in the default GPU
Merge pull request #504 from leelurch/Config-Example-Ubuntu14.04
Merge pull request #507 from longjon/set-device-early
Add comment to Makefile.config.example about DEBUG flag issue in OSX per #171.
in Caffe::SetDevice, call cudaSetDevice before Get
Merge pull request #431 from mavenlin/lmdb
Add comment for how to set the CUDA path when cuda tools are installed by the package manager.
fix string compare error
add lmdb support for compute_image_mean
add lmdb support for convert_imageset
Merge pull request #495 from jeffdonahue/refactor-net
add net surgery link to docs (+ drop old comment)
unify data layer tests: was copied four times for all combinations of cpu/gpu and leveldb/lmdb; now just one copy of each test body
unify test_data_layer tests
lint
fixed cpplint error
add tests for lmdb of datalayer (copied from test_data_layer.cpp)
add option for lmdb
Merge pull request #455 from shelhamer/pycaffe-save
refactor Net::Init to call helpers AppendBottom and AppendTop
make Net::Init loop indices clearer
Merge pull request #496 from jeffdonahue/test-net-use-dummy-data
make test_net use DUMMY_DATA instead of leveldb
make notebook for net surgery of fully-convolutional model
define fully-convolutional imagenet model
save from python for net surgery
Merge pull request #482 from shelhamer/rcnn-detector-example
Merge pull request #469 from weinman/grayscale-io-convert
pycaffe: leave grayscale images gray according to arg
drop learning rates and decays from deploy model
groom install docs
fix clang compilation problem w/ DummyDataLayer
finish R-CNN detection example
make selective search proposals with R-CNN configuration
edit detection example, include R-CNN NMS
make R-CNN the Caffe detection example
pycaffe Detector crops with surrounding context
fix old detect.py default
lint dummy data layer
Merge pull request #480 from jeffdonahue/dummy-data-layer
add DummyDataLayer tests
add DummyDataLayer
fix ArgMaxLayer bug in num bottom blobs decl. pointed out by @sguada
Merge pull request #479 from jeffdonahue/declare-layer-names-and-numblobs
add fish bike example image
move MemoryDataLayer decl. from vision_layers.hpp to data_layers.hpp
layers declare their names and number of input/output blobs, and don't check top/bottom blob counts explicitly in SetUp; instead call base Layer::SetUp.
fix Makefile build dir link upgrade bug reported by @jamt9000
Changed variable name: iscolor to is_color.
Merge pull request #473 from shelhamer/pad-max-pooling
check the last pooling in padding and add padded max pooling test
padding for max pooling
Merge pull request #475 from jeffdonahue/tanh-fixes
Make TanH cleaner, more efficient, and possible to use in-place
Merge pull request #471 from jeffdonahue/debug-release-build-dirs
Update docs on building boost on OSX for the python wrappers
Merge pull request #466 from robcurrie/dev
update .gitignore appropriately for separate debug/release build dirs
compile debug/release into separate directories so you don't have to rebuild the whole thing to switch back and forth
Added an iscolor flag to io.cpp method ReadImageToDatum to handle grayscale images and a corresponding commandline flag [-g] to convert_imageset.cpp.
Update docs on building boost on OSX for the python wrappers
fix OSX 10.9 homebrew CXX doc
fix OSX 10.9 homebrew CXX doc
Merge pull request #422 from sguada/threshold_layer
Un comment Test GPUs cases, fixed ThresholdLayer.cu
Comment Test GPUs cases
Make lint happy
Fixed call to ThresholdForward in ThresholdLayer.cu
Fixed type in ThresholdLayer.cu
Fixed typo in Threshold Layer definition
Added ForwardGPU to ThresholdLayer and to the tests
Added Threshold layer to neuron_layers.hpp
Corrected conditions in test_threshold
Fix typo in test_threshold ThresholdParameter
Added the code for threshold_layer to the repo
Added NeuronLayer<Dtype>::SetUp(bottom, top) to ThresholdLayer
Added threshold setting test
Fixed name of blob_bottom_
Fixed name of threshold_ var
Fixed ThresholdParam
Test for Threshold layer
Merge pull request #459 from shelhamer/python-net-preprocessing-members
caffe.Net preprocessing members belong to object, not class
Merge pull request #459 from shelhamer/python-net-preprocessing-members
caffe.Net preprocessing members belong to object, not class
Merge pull request #445 from jeffdonahue/convert_imageset_resize_option
convert imageset comment fixup
Merge pull request #456 from longjon/spurious-ldflags
don't pass LDFLAGS when only compiling
10.9 install doc formatting
10.9 install doc formatting
Back-merge recent fixes from master to dev
fix OSX 10.9 compiler/stdlib override for latest homebrew
Merge pull request #448 from jeffdonahue/sguada-fix_maxpooling
merge caffe_set definitions; define for int as well
add tests for maxpooling layer forward, and for maxpooling with top mask
optionally output the mask to a top blob instead of storing internally
make a Blob<unsigned int> and use in dropout layer
use a Blob<int> instead of a SyncedMemory to store max_idx_
bugfix: setting count to the top count in backward doesn't process all of the bottom (assuming the bottom is larger, which happens for nontrivial poolsize>1)
mask should be const in backward pass
remove commented out code
lint and make compilable (using static_cast's found a couple bugs at compile time)
Adapted to V1 proto definition, test don't pass
Commented Atomic Add, back to loop in GPU MaxPoolBackward
Attempt to use AtomicAdd but it seems slower
Added test for maxpool layer followed by dropout
Use loops in GPU again to avoid over-writting of bottom_diff
Fixed parameter order
Cleaned prints from test_pooling_layer.cpp
Set bottom_diff to 0 and remove Async memcopy
Remove top_data from backward Max Pooling
Use mask_idx to compute backward Max Pooling
Added test for  Pooling layer GPU
Added max_idx to Pooling layer GPU
Default mask idx is -1
Added max_idx to Pooling layer CPU
Don't modify data pointers in im2col loop
add convert_imageset option to resize images; use in convert_imageset.cpp and document
follow-up on #443 to invert k channels (instead of 3)
Correctly invert the swapping of colour channels
follow-up on #443 to invert k channels (instead of 3)
Merge pull request #443 from jamt9000/correct-deprocess
Correctly invert the swapping of colour channels
Merge pull request #433 from shelhamer/eltwise
commment, lint
weight elementwise sum with per-blob coefficients
link presentation on dropbox (was self-hosted during a dropbox issue)
link to demo
make sum the default eltwise operation
fix layer name in logging
Merge pull request #435 from shelhamer/v1-models
fix draw_net python script
release v1 model defs + weights
Merge pull request #434 from shelhamer/little-cat
reduce example image size
point out @niuzhiheng's work on the Windows port
add EltwiseLayer docstring
Elementwise layer learns summation
add caffe_gpu_add() and caffe_gpu_sub()
EltwiseProductLayer -> EltwiseLayer for generality
fix test_all path in docs
Revert "setting canonical random seed"
Merge pull request #421 from sguada/argmax_layer
setting canonical random seed
Fixed lint errors due to ArgmaxLayer
Documented ArgMax layer in vision_layers.hpp
corrected the caffe.proto ids
Change ArgMaxLayerParam to ArgMaxParam for consitency
Change ThresholdLayer to ArgMaxLayer in test_argmax
Fixed name of blob_bottom_
Fixed name of ArgMaxLayerParameter
Added missing ;
Added FLT_MAX to argmax layer
Fix types of ArgMax Layers params
Fixed numbers in proto and name of ArgMaxParameter
Added Test for ArgMax Layer
Added ArgMax Layer
Merge pull request #404 from jeffdonahue/net-param-in-solver
link canonical bvlc site
link canonical bvlc site
fix detection notebook link
fix detection notebook link
Merge pull request #429 from shelhamer/next
Back-merge changes in master
Merge pull request #311 from shelhamer/python-fixes
update notebook examples with new wrapper usage, re-organize
preprocess single inputs instead of lists
windowed detection in python
squash infuriating loop assignment bug in batching
image classification in python
fix padding for the last batch
split drawnet into module code and script
add caffe.io submodule for conversions, image loading and resizing
fix python mean subtraction
Merge pull request #376 from sergeyk/layer_reorg
Don't modify index in im2col kernel loop
Incorporated Evan’s comments for neuron layers
Cosmetic change in ConcatLayer
Lil’ more docstring, and cosmetic change in EuclideanLossLayer
fwd/back math docs for neuron layers
drop cute names in favor of Net.{pre,de}process() for input formatting
Net.caffeinate() and Net.decaffeinate() format/unformat lists
take blob args as ndarrays and assign on the python side
Cosmetic change in prep for data layer work
Split all loss layers into own .cpp files
layer definition reorganization and documentation - split out neuron, loss, and data layers into own header files - added LossLayer class with common SetUp checks - in-progress concise documentation of each layer's purpose
resize to input dimensions when formatting in python
replace iterator with indices for consistency
python style
fix accidental revert of Init() from f5c28581
batch inputs in python by forward_all() and forward_backward_all()
don't squeeze blob arrays for python
python forward() and backward() extract any blobs and diffs
python Net.backward() helper and Net.BackwardPrefilled()
bad forward/backward inputs throw exceptions instead of crashing python
pycaffe Net.forward() helper
set input preprocessing per blob in python
expose input and output blob names to python as lists
Merge pull request #417 from shelhamer/create-and-write-proto
fix workaround in net prototxt upgrade
Write/create/truncate prototxt when saving to fix #341
pycaffe comments, lint
add python io getters, mean helper, and image caffeinator/decaffeinator
make python wrapper mean match binaryproto dimensions
match existing python formatting
Merge pull request #414 from shelhamer/net-output-blobs
net knows output blobs
Merge pull request #413 from shelhamer/cublas-status-not-supported
add cublas status in cuda 6 to fix warning
Merge pull request #406 from jeffdonahue/makefile-include-bug
fix Makefile bug - HXX_SRCS was things that don't end in .hpp, instead of things that do...
require either train_net or train_net_param to be specified
fix proto comment for multiple test nets
add script to run lenet_consolidated_solver and add comment with results for first/last 500 iterations
lint and two test_iters in lenet_consolidated_solver
multiple test_iter
add a lenet example of specifying train/test net directly in solver; multiple test nets
allow multiple test nets
log {Net,Solver}Parameters on Init
specify NetParameters directly in the SolverParameter
Merge pull request #403 from jeffdonahue/solver-mode-enum
make solver_mode an enum with CPU and GPU -- fully backwards compatible with old 0/1 style
Merge pull request #396 from longjon/math-includes
improve includes in util/math_function.hpp
note bug in cifar10 full with CPU computation
bundle presentation in gh-pages for now...
Merge pull request #294 from longjon/memory-data-layer
fix lint error in syncedmem.hpp
pycaffe: allow 1d labels to be passed to set_input_arrays
pycaffe: add Net.set_input_arrays for input from numpy
pycaffe: store a shared_ptr<CaffeNet> in SGDSolver
pycaffe: let boost pass shared_ptr<CaffeNet>
add basic tests for MemoryDataLayer
add size accessors to MemoryDataLayer
add MemoryDataLayer for reading input from contiguous blocks of memory
add set_cpu_data to Blob and SyncedMemory
Merge pull request #378 from longjon/no-merge-duplicates
note the last added layer/params in caffe.proto to prevent conflicts
Merge pull request #377 from sguada/fix_initial_test
Keep uniform test messages for all the test
rollback 8368818, does not build
Add Sublime Text project settings to gitignore
Handling CUBLAS_STATUS_NOT_SUPPORTED to suppress warning
Merge pull request #370 from shelhamer/test-net-polish
fix test_net to upgrade params from v0 if needed
default test net device to 0 and log device chosen
set seed in neuron and power layer tests for deterministic results
Merge pull request #367 from shelhamer/randomize-test-order
proofreading and trivial polish
add device id arg to test_net (fix #232)
Merge pull request #303 from longjon/hinge-loss-layer
Merge pull request #368 from shelhamer/fix-data-layer-sequence-tests
scope data layer sequence tests to avoid leveldb contention
set phase in dropout tests
randomize order of test execution by make runtest
Merge pull request #366 from shelhamer/test-phase-fix
set TRAIN in CommonTest.TestPhase
test HingeLossLayer
make gradient checker's kink use feature absolute value
add HingeLossLayer for one-vs-all hinge loss
Merge pull request #365 from longjon/pycaffe-empty-nets
pycaffe: add unary CaffeNet constructor for uninitialized nets
Merge pull request #363 from jeffdonahue/speedup-gradient-check
eltwise gradient checker
move analytic gradient computation outside loop and store -- saves a lot of time
Merge pull request #364 from niuzhiheng/dev
note pydot dependency of model visualization
Update the drawnet.py to reflect the recent revised net definition.
Merge pull request #352 from jeffdonahue/solver-seed
Merge pull request #357 from jeffdonahue/test-on-iter-0
test on "0th iteration" -- before doing any training
add caffe/random_fn lint rule to check for use of rand, rand_r, random
replace std::shuffle with version using prefetch rng; improve unit test
replace remaining uses of rand() with caffe_rng_rand()
prefetch_rng in window_data_layer
prefetch_rng in ImageDataLayer
test scale param
make seed test pass by setting up new layer to generate the 2nd sequence
cleanup data_layer, add prefetch_rng_ field to it and use instead of rand -- seeded tests still fail
add tests for random crop sequence -- currently both fail
add data layer crop tests
add random_seed field to SolverParameter and have solver use it -- already works for lenet, doesn't work for imagenet w/ rand() calls
add forward tests (via reference impl) for SigmoidCrossEntropyLayer
Merge pull request #350 from longjon/finicky-exhaustive
make CheckGradientExhaustive fail for topless layers
Merge pull request #348 from jeffdonahue/datalayer-singleton-bugfix
do the same as prev commit for ImageDataLayer
fix bug where DataLayerPrefetch creates its own Caffe singleton, causing the phase to always be set to TRAIN (always random crops) and RNG failures
fix typo pointed out by @yinxusen
Comment current forward/backward responsibilities
Proofread install docs
Merge pull request #339 from sergeyk/dev
installation doc update
Merge pull request #336 from jeffdonahue/fix-rng-segfault
fix examples path in mnist leveldb sh
Merge pull request #332 from jeffdonahue/share-trained-layers
remove now unused set_generator and related code
pass caffe rng ref into variate_generator constructor instead of having caffe rng adopt its state
remove unnecessary return from void set_generator
note support for non-MKL installation in dev
add ShareTrainedLayersWith method and use for test net in solver
Merge pull request #330 from jeffdonahue/mnist-autoencoder-example
change to correct next layer id for merge
clear sigmoid top vec at initialization
add sigmoid cross ent layer unit tests
Merge pull request #327 from shelhamer/alexnet
mnist_autoencoder_solver cleanup
change lenet dir to 'mnist' in docs
make solver able to compute and display test loss
mnist autoencoder test proto bugfix: add sigmoid layer before loss
enable DataLayer to output unlabeled data
add mnist autoencoder example necessities (sigmoid cross entropy loss layer, sparse gaussian filler)
include pretrained snapshot and performance details
Document AlexNet model, include download script
define AlexNet architecture
rename lenet dir to mnist
Give choice of ATLAS, MKL, and OpenBLAS (with option to override paths)
rename python include config var to match lib
Merge pull request #325 from AlOa/OpenBlas
Add possibility to use OpenBlas
Merge pull request #318 from jeffdonahue/blob-copy-by-reference
Merge pull request #319 from jeffdonahue/sigmoid-optimization
sigmoid layer backward pass optimization: don't recompute forward pass
change Adopt -> Share as suggested by kloudkl
add Adopt{Data,Diff} methods to blobs to enable "virtual copying"
add unit tests for cpu/gpu copy functions
change some unnecessary TYPED_TESTs to TEST_Fs
fix lint errors by adding 'explicit' to new single arg pycaffe constructors
polished ignore
polished ignore
Back-merge docs and example image changes from `master` to `dev`
Merge pull request #310 from jeffdonahue/clang-test-power-layer-fixes
add using std::isnan and use this-> when calling Test{For,Back}ward
fix osx 10.9 condition in Makefile
include vecLib BLAS dir on osx
Merge pull request #286 from longjon/pycaffe-solver
change true_std to intended bernoulli_std
Merge pull request #297 from jeffdonahue/rng-bug
more rng test cleanup
re-time imagenet example on k20, instead of my laptop
change *Plus* tests to *Times* tests because the Plus tests don't actually check for uncorrelated RNG results
add analogous caffe_gpu_rng_* functions for gaussian and uniform, and add test cases
have rng_stream initialize RNG if not already initialized
make RNG function outputs the last argument per Google C++ style guidelines
make RNG function names more similar to other caffe math function names
gpu_hamming_distance fails unit test with fixed RNG; mark it NOT_IMPLEMENTED with TODO to fix and disable its unit test
cleanup RNG unit tests
make rng_ a private member of Generator
cleanup test_math_functions
comment to explain the purpose of Caffe::set_generator
fix bernoulli*bernoulli test, now all pass
call caffe_set_rng at the end of each vRng function to maintain state
add bernoulli*bernoulli test
cleanup log messages
add analogous test for uniform instead of gaussian
add test demonstrating weird boost RNG issue when sampling from a gaussian followed by a bernoulli
Merge pull request #305 from shelhamer/install-doc-blas-platform
Merge pull request #309 from shelhamer/comment-matlab-config
Comment out MATLAB by default in Makefile.config
rename doc deploy script for better tab completion
Drop Lena image in favor of a cute cat photo
auto-configure linux/osx build differences
trivial makefile grooming
Merge pull request #273 from jeffdonahue/lrn-map-layer
update proto field IDs from placeholder values
cleanup power layer test suite
minor unit test cleanup
cleanup extra LRN method names
don't recompute pre_pad
remove unnecessary local variables from EltwiseProductLayer
minor polishing
replace old cifar full with within channel LRN (per cuda-convnet layers-18pct) -- slightly slower (5000 iters now takes 6:57; took 6:43 previously), but slightly more accurate (exactly 82% test accuracy; got 81.65% before)
merge LRNMapLayer into LRNLayer with norm_region proto field
fix some param bugs
add cifar example using LRN_MAP (just like the cuda-convnet layers-18pct architecture) instead of LRN
use bvlc copyright
use split layer in LRNMapLayer
bug fix: average pooling already divides by N^2
add padding for average pooling
use average pool instead of conv
add unit tests for new layer types
add LRN within map layer and dependencies (eltwise product and power)
blas install docs, other install polish
Back-merge documentation and fixes
format installation docs, add links
Add hdf5 requirements to 10.9 notes, drop cmake (not linked)
fix im2col height/width bound check bug (issue #284 identified by @kmatzen)
Merge pull request #298 from jeffdonahue/im2col-nonsquare-bug
Merge pull request #302 from sguada/protobuf_limit
Doubled protobuf Bytes Limit
fix im2col height/width bound check bug (issue #284 identified by @kmatzen)
separate CPU from GPU ConvolutionLayerTests
make height/width of input dims in conv layer tests more different to expose bug (GPU tests now fail due to the bug)
pycaffe: expose SGDSolver.solve
pycaffe: introduce CheckFile helper
pycaffe: expose SGDSolver.net
switch from inheritance to directly overriding methods for caffe.Net
make Solver::net return a shared_ptr rather than a raw pointer
pycaffe: expose SGDSolver
add string constructor to Solver (analogous to Net)
strip confusing confusing comment about shuffling files
Revert "Fix segfault." (python)
Merge pull request #277 from jeffdonahue/makefile-improvements
gitignore python/caffe/proto/; superclean ignore data dir
add /etc/rc.local hint for boot configuration of gpus
Merge pull request #287 from robwhess/dev
Merge pull request #288 from beam2d/fix-blob-params-order
Fix parameter orders in declaration of Reshape
Include k40 images per day benchmark
drop caffe presentation in favor of dropbox link
make build_docs.sh script work from anywhere
proofread, fix dead link, standardize NVIDIA capitalization
Fix segfault.
Added Link in index.md to perfomance_hardware.md
Added Performance and Hardware Tips
include build/ before other dirs so old proto built files in src/ and include/ don't interfere
remove silly thing where I copied proto headers to a separate build/include dir
matcaffe fixes
fix test bugs and minor cleanup
cleanup python build and clean
compile test bins directly into build/test
add test header dependency and fix mat targets
minor cleanup
libcaffe.* in build/lib/
everything prints a blank line after compiling
lots of corrections to dependencies etc., things seem to mostly build coherently now
messed around with Makefile - currently in very messy state
cleanup superclean output
put proto-generated .cc and .h files in build directory
create softlink to test directory at build/test
create superclean Makefile target to delete all files with generated extensions
put TEST_GPUID in Makefile.config
Merge pull request #223 from sguada/improved_matcaffe
Merge pull request #278 from kloudkl/log_error_string_in_check_macro
Merge pull request #283 from jeffdonahue/boost-rand-seed
seed boost rng with cluster_seedgen by default
Add a space before the error string
Fix cpplint errors
Add curandGetErrorString and use it to redefine CURAND_CHECK
Add caffe::cublasGetErrorString and redefine CUBLAS_CHECK with it
Define CUDA_POST_KERNEL_CHECK with CUDA_CHECK
Log error string rather than enum value in CUDA_CHECK
Removed empty space, verified lint
Added default values to matcaffe_batch for testing
Added matcaffe_init to easy reuse of caffe initialization
Removed fillers from imagenet_deploy
Created reset command and changed END to NULL again
Added prints to matcaffe_demo stages
Cleaned matcaffe.cpp to pass lint
Changed matcaffe_demo to return maxlabel
Changed Copyright to BVLC
Resolved merge conflicts
Merge pull request #275 from kloudkl/fix_kernel_for_loop_in_macro
Use CUDA_KERNEL_LOOP in the macro DEFINE_AND_INSTANTIATE_GPU_UNARY_FUNC
Merge pull request #272 from kloudkl/gpu_hamming_distance
Merge pull request #271 from jeffdonahue/lint-bvlc-copyright
Implement and test gpu hamming distance
Rename caffe_hamming_distance into caffe_cpu_hamming_distance
make lint check for 'Copyright [year] BVLC and contributors.'
compile the copyright regex
imagenet fix: ilvsrc -> ilsvrc
Merge pull request #219 from jeffdonahue/refactor-layerparam-proto
rename test_innerproduct_layer to test_inner_product_layer
move ReadNetParamsFrom{Text,Binary}File into util
add NetParameterPrettyPrint so that upgrade tool prints inputs before layers
update docs (and a couple comments) for refactored layerparam
fix upgrade_net_proto names
minor cleanup
add support for hdf5 output layer
cleaner version of refactoring with fields added to LayerConnection (which retains an optional V0LayerParameter field for legacy support) and LayerConnection renamed to LayerParameter
some post rebase fixes -- copyright, hdf5_output layer (still need to incorporate into util/upgrade_proto)
rollback previous commit adding version number to NetParameter -- going a different route
add NetParameter required version number as breaking change for V0NetParameter
allow upgrade_net_proto to also read/write binary protos (e.g. saved models)
regenerate imagenet_val feature extraction prototxt with missing IMAGE_DATA params
make all tools backwards compatible with v0 net param
upgrade images layer
upgrade remaining prototxts
upgrade_net_proto: allow input files already in new proto format
fix upgrade_net_proto name
incorporate WindowDataLayer into V0Upgrade and add tests
update deprecated protos to latest dev versions
make test_protobuf use NONE for dummy layer instead of SPLIT
some naming standardization: ImagesLayer -> ImageDataLayer (like other data layers), and load_hdf5_file_data -> LoadHDF5FileData
alphabetize classes in vision_layers.hpp
some cleanup - lowercase layer class member variable names
remove padding layer
fix test_net for refactor
incorporate WindowDataLayer
rebase and fix stuff, incorporate image and padding layers
fix layertype alphabetization
fix lint errors
fix post-rebase param bugs
convert existing models to new format (used tools/upgrade_net_proto with no manual editing)
LayerType enum
put inputs before layers in the proto so they print in that order
add test for input/input_dim and fix bug, wasn't copying input
add upgrade_net_proto tool
fix insert_splits for new layer param format
add test which includes upgraded params
add imagenet upgrade test and fix bug in upgrade_proto
more padding layer upgrade tests
imagenet padding upgrade test
set correct bottom blob name in upgraded conv layer
function to upgrade padding layers
make solver use upgrade_proto (by constructing net with a string) and fix upgrade_proto bugs
add deprecated protos to PROTO_OBJS in makefile so things compile; other minor cleanup of includes etc
make ReadProtoFromTextFile not die on parse failure; add ReadProtoFromTextFileOrDie which has the old functionality
add V0NetParameter and UpgradeV0Net
caffe.proto: layer->layers
add v0->v1 'bridge' proto and add util that uses it
move caffe.proto.v0 -> deprecated/caffe.v0.proto and add separate target makefile target for it
update tests for new proto format; now they compile
changes to layers etc to make 'make all' run successfully under new caffe.proto
add duplicated params from InnerProductParam to ConvolutionParam and PoolingParam etc, create InfogainLossParam
HDF5DataParameter message and concat_param
NetParameter.layers -> layer
remove LayerConnection from proto, bottom and top now in LayerParameter
move LayerParameter and individual layer param messages to bottom of caffe.proto
move individual layer parameters to individual proto messages
create file caffe.proto.v0 which duplicates current caffe.proto
fix caffe.proto style bugs
Merge pull request #266 from longjon/toomanyargs
Merge pull request #268 from longjon/debug
add DEBUG option to Makefile/Makefile.config.example
tools should have nonzero error exit codes
passing too many args to tool binaries is an error
Merge pull request #265 from jeffdonahue/hdf5-output-tmpfile-fix
change hdf5 output layer test output file to a tmpnam rather than hard-coded path
installation proofreading, split parallel compilation
Merge pull request #255 from shelhamer/copyright-credit
note copyright assignment in development guide
Standardize copyright, add root-level CONTRIBUTORS credit
Merge pull request #260 from kloudkl/fix_doc_typos
removing lena in favor of cat
Add packages installation command for CentOS/RHEL
Fix imagenet pretrained links
Add in doc how to remove leveldb dir if existed
Fix feature extraction reference model path and file list command bugs
fixed compilation error on window_data_layer.cu in 10.8
Add headers to build on OS X
Separate WindowDataLayer::Forward_gpu into a cu file
Separate ImagesLayer::Forward_gpu into a cu file
Merge pull request #201 from kloudkl/more_math_functions
Merge pull request #252 from kloudkl/hdf5_output_layer
Separate HDF5OutputLayer::Forward_gpu/Backward_gpu into cu file
Fixed CPPLint errors related to math funtions
Rename signbit in macros to sgnbit to avoid conflicts with std::signbit
Add signbit math func, simplify GPU defs & instantiations with a macro
Add and test non-in-place scale math functions for CPU and GPU
Use macro to simplify element wise cpu math functions
Add and test element wise abs math functions for CPU and GPU
Instantiate caffe_cpu_sign for float and double
Add and test element wise sign math funtions for CPU and GPU
Add and test sum of absolute values math functions for CPU and GPU
Rebase and change the HDF5OutputLayer::Forward/Backward signatures
Add HDF5OutputLayer to the layer factory
Implement and test HDF5OutputLayer
Implement HDF5 save dataset IO utility function
Merge pull request #165 from BVLC/boost-eigen
Set copyright to BVLC and contributors.
Hide boost rng behind facade for osx compatibility
lint
clean up residual mkl comments and code
Added extern C wrapper to cblas.h include
Fixed order of cblas and atlas linker flags
comment out stray mkl includes
make MKL switch surprise-proof
rewrite MKL flag note, polish makefile
major refactoring allow coexistence of MKL and non-MKL cases
Replace atlas with multithreaded OpenBLAS to speed-up on multi-core CPU
fix bernoulli generator bug
add bernoulli rng test to demonstrate bug (generates all 0s unless p == 1)
change all Rng's to use variate_generator for consistency
use boost variate_generator to pass tests w/ boost 1.46 (Gaussian filler previously filled in all NaNs for me, making many tests fail)
make uniform distribution usage compatible with boost 1.46
mean_bound and sample_mean need referencing with this
nextafter templates off one type
relax precision of MultinomialLogisticLossLayer test
Fix math funcs, add tests, change Eigen Map to unaligned for lrn_layer
Fix test stochastic pooling stepsize/threshold to be same as max pooling
Fixed FlattenLayer Backward_cpu/gpu have no return value
Fixed uniform distribution upper bound to be inclusive
compile caffe without MKL (dependency replaced by boost::random, Eigen3)
Merge pull request #247 from jeffdonahue/loss-in-forward-window-data-layer
loss in forward pass fix for window data layer
Merge pull request #209 from jeffdonahue/loss-in-forward-pass
Back-merge documentation and script fixes
fix script path incantation
convert css indentation to spaces
fix cifar10 leveldb creation path
wget without checking certificate for dropbox (dodge complaint on linux)
docs: added list of contributors
minor style update of docs
Fix to #161 - signficantly change the documentation file - link to it from index.md - remove the image resizing script, since (a) it does not work, (b) is obviated by using ImagesLayer - add sample prototxt that uses ImagesLayer.
Merge pull request #161 from kloudkl/simplify_feature_extraction
minor cleanup in rcnn-finetuning -- rcnn feature computation tested at this commit (in addition to all caffe unit tests passing)
cleanup matlab demo
add initialization key for verifying state
demo on how to get net weights using the matlab interface
return model weights
keep DLOG (revert accidental switch to LOG)
file pascal finetuning prototxt examples and fix paths
set default to the best value
some cleanup
fix paths
support for tightest square mode while finetuning
10x learning rate for fine tuning makes a big difference
support for adding padding to windows in the window_data_layer
Code that was used to finetune with reasonable success
some major bug fixes (includes some to-be-removed debugging code)
adjustments to try to match the setup for fine tuning with cuda-convnet
define pascal finetuning models
add window data layer
post rebase fixes: images layer and padding layer compute loss in forward
null pointer defaults for forward loss outputs
loss in forward pass for concat layer (thought i'd rebased to latest dev but apparently not)
fix softmax loss layer bug; all tests pass
remove accidentally added empty line
revert unnecessary reordering of lines in softmaxwithlosslayer backward
gradient checker optimization with forward pass loss: only need to run backward pass to compute analytic gradient (the thing being checked) now
test_gradient_check_util: blobid -> blob_id
make tests compile and pass
fix net_speed_benchmark so 'make all' works
change specification of forward/backward function and fix layer definitions appropriately
Merge pull request #221 from jamt9000/fix-dump-network
Merge pull request #242 from kloudkl/script
File naming convention requires that two words be split by a underscore
Wget should never be quiet
Fix shell script current dir bad substition errors
Explain how to get the mean image of ILSVRC
Change generate file list python script path in feature extraction doc
Removing feature binarization and image retrieval examples
Move binarize_features, retrieve_images to examples/feauture_extraction
Add documentation for the feature extraction demo
Add a python script to generate a list of all the files in a directory
Don't create a new batch after all the feature vectors have been saved
Fix cpplint errors for Net, its tests and feature related 3 examples
Use lowercase underscore naming convention for Net blob & layer getters
Move extract_features, binarize_features, retrieve_images to tools/
Save and load data correctly in feat extracion, binarization and IR demo
Change feature binarization threshold to be the mean of all the values  rather than zero in the feature binarization example
Fix saving real valued feature bug in the feature extraction example
Fix bugs in the image retrieval example
Fix bugs of the feature binarization example
Enhance help, log message & format of the feature extraction example
Fix bugs in the feature extraction example
Add __builtin_popcount* based fast Hamming distance math function
Simplify image retrieval example to use binary features directly
Add feature binarization example
Add feature extraction example
Add image retrieval example
Add and test Net::HasLayer and GetLayerByName
Add and test Net::HasBlob and GetBlob to simplify feature extraction
Remove cudaSetDevice(1)
Merge pull request #231 from BVLC/next
arrange example images, update paths, bring back imagenet_pretrained
Merge pull request #236 from jeffdonahue/test-all-bin-makefile-deps
also fix for runtest
add libcaffe.a to TEST_ALL_BIN dependencies in Makefile
Merge pull request #240 from jeffdonahue/rm-cuda-kernel-loop-comments
use CUDA_KERNEL_LOOP in padding layer
fix remaining lint errors
fix remaining issues related to CUDA_KERNEL_LOOP
Merge pull request #239 from jeffdonahue/fix-kernel-loop-macro
fix kernel loop bugs, compiles and passes all tests
addd CUDA_KERNEL_LOOP macro
lint, except for rand/rand_r
drop models/ in favor of examples/
fix README links to presentation and development section
build_docs script
groom docs, move Caffe presentation to dropbox
Merge pull request #234 from sergeyk/updating_docs
minor fixes suggested by evan
removing notebooks in docs, updating instructions
minor fix to caffe model DL script
Merge pull request #230 from kloudkl/get_model_script
Set phase to TRAIN when performing backward pass
Merge pull request #229 from kloudkl/minor_change
Add support for md5 checksum on OS X
Avoid repeatedly downloading caffe reference imagenet model
Display total num of processed files after computing image mean
minor mnist example update
link draft CIFAR-10 example
sort layer factory's list alphabetically
fix style bugs in new layers' proto fields
Back-merge documentation and historical PRs to master
proofreading
Merge pull request #226 from longjon/imagenet-vis
Draft CIFAR-10 doc and cleanup example
Merge pull request #228 from longjon/pycaffe-exceptions
Raise Python exceptions if CaffeNet input files don't exist
Add comment explaining placement of system headers in C++ Python module
Merge pull request #227 from shelhamer/padding-deprecation
Add the feature and filter visualization example (Lena) to docs
Add ImageNet Lena filter visualization example
style: line continuation spacing
bring back padding test and lint it
bring back padding layer with deprecation notice
Merge pull request #203 from sergeyk/hdf5_data
Merge pull request #199 from longjon/pycaffe-ordereddict
Move semicolon to appease lint
minor
Lint errors fixed, except still using stream.
Merge pull request #222 from jeffdonahue/test-all-bin-gpuid
Making HDF5 blob data non-mutable for copy (minor)
make runtest with TEST_ALL_BIN obey TEST_GPUID
Fix wrong argv check for whether a backward pass should be done
Prevent blob from being freed at end of if statement scope
relax timing checks for commodity GPUs
Merge pull request #179 from erictzeng/test_all
Fix a test assuming CPU mode without explicitly setting it.
HDF5 data now loaded into Blobs; cleaner interface
readme.md updated with more info about development
HDF5DataLayer source is now a list of filenames
DRYing and documenting HDF5 loading code.
Merge pull request #217 from tdomhan/multidhdf5
support for more than 2 dimensions in hdf5 files
Fix indentation in C++ Python module
Add extra comment on vector_indexing_suite to _caffe.cpp
Remove spurious constructors from CaffeBlob and CaffeBlobWrap
Add names to the blobs returned by CaffeLayer
Expose caffe.Net.params as an OrderedDict
Expose layers and remove now-redundant params in Python interface
add hdf5 dependency to install guide
Publish the Caffe presentation, pi day edition
note CUDA lib without CUDA driver install for CPU mode
fix wrapper example paths
More documentation on running tests (including --gtest_filter info).
Compile a binary to run all tests at once.
Merge pull request #120 from sguada/images_layer
Merge pull request #136 from kloudkl/cuda_timing
Merge pull request #184 from chyojn/cifar10_model_script
Update imagenet/wrapper.py to use the new Net interface
Update detector.py to use the new Net/blobs interface
Use an OrderedDict for caffe.Net.blobs
Add a pass-through Python wrapper of _caffe.CaffeNet
Rename pycaffe.cpp -> _caffe.cpp in preparation for python wrapper
pycaffe: blobs and params are properties, not methods
Merge pull request #191 from sguada/print_memory
Merge pull request #200 from longjon/pycaffe-forwardprefilled
pycaffe: expose ForwardPrefilled
Merge pull request #134 from mavenlin/computemean
move if outside of forloop
compute data mean for float_data
Update README.md to fix missing } in bibtex
Changed display top shape to include num and count, Memory required by Data
Log memory usage while loading a Net
Merge pull request #187 from yosinski/doc-up
Fixed command path in documentation
Fix the cpplint errors for benchmark Timer
Add state machine, boost::posix_time based cpu timer & tests for Timer
Replace CPU timer with newly added Timer to benchmark net speed
Add Timer to wrap CPU clock_t and GPU cudaEvent_t based timing
Synchronize GPU before CPU timers start and stop in net_speed_benchmark
remove specific device id from solver proto
move model's pad layer into conv layer; add script to create db and train net by 80sec and 18pct model
add cifar10 80sec and 18pct models, according to convnet
Back-merge documentation updates from master
Draft development guidelines, link from README
minor readme polish
Merge pull request #181 from chyojn/absolute_path_of_script
Merge pull request #125 from sguada/concat_layer
use absolute path in script
Splited concat_layer into .cpp and .cu, cleaned lint errors
Fixed test to pass and don't exhaustive search since it takes too long
Added Tests for Concat Layer, and passed
Added concat_dim to caffe.proto and ConcatLayer to set of layers
Code for concat_layer for concat along num and channels dimensions
fix include order for pycaffe on osx, override lint
add hardware notes to installation
outline pull request etiquette
Merge pull request #176 from jeffdonahue/osx-make-lint-fix
fix 'make lint' in OSX: seems that NONGEN_CXX_SRCS wasn't getting populated in OSX due to some disagreement in the regex formatting in find...give up on that and use an ugly but reliable chain of -name ... -or -name ...
Merge pull request #172 from erictzeng/split_cuda
polish doc build and deploy and allow other remotes
fix path for mnist leveldb creation
fix examples shell scripts: too many dollar signs, not enough coffee
fix formatting + notebook url of 8c245b5
update detection example post re-arrangement in #124
Splitting source files between CUDA and CPU code.
Merge pull request #168 from jeffdonahue/fix-lint-bugs
fix python/matlab wrapper bugs introduced by lint; change linter->lint in Makefile
make lint will not rerun if successful and no source files have been changed; saves output to build/cpp_lint.log (or build/cpp_lint.error_log on failure)
Merge pull request #163 from jeffdonahue/linter
cpplint.py -> cpp_lint.py and NOLINT_NEXTLINE -> NOLINT_NEXT_LINE
add new tools dir to linted dir list
fix linter errors in examples
add examples, python, matlab to NONGEN_CXX_SRCS so they are linted as well
fix compiler warning for test_hdf5data_layer
fix post-rebase linter errors
long -> int64_t; all linter errors fixed. woohoo!
handle linter stream errors
allow TODO without username
make test_gradient_check_util methods use pointers for non-const inputs (also change EXPECT_LT and EXPECT_GT pair to EXPECT_NEAR)
fix most linter errors
add NOLINT_NEXTLINE to suppress linter errors on nextline
exclude proto generated files from lint
add hpp to valid cpplint extensions
fix matcaffe and pycaffe linter errors
suppress linter errors due to not including the directory when naming .h files
Reverse the order of hdf5_hl hdf5 as LIBRARIES in Makefile
add cpplint.py and "make lint" to run on all c source files
Merge pull request #147 from sergeyk/hdf5_data
name blobs and params for their layers in python wrapper
minor comment edit
HDF5DataLayer, with test.
Adding GPU coverage to the DataLayer test.
Merge pull request #128 from mavenlin/pad-im2col
remove cuda_timer as is no longer needed
remove padding_layer and its test
unified to padding aware version
remove padding layers in imagenet definitions
remove the pad=0 case in conv_layer and im2col_layer
add code to measure timing
add test code to test the padding aware im2col col2im functions
implemented padding aware im2col and col2im functions
Merge pull request #167 from BVLC/next
Define split layer (merge trick)
Merge pull request #129 from jeffdonahue/dags-by-split
minor cleanup; only get blob_name if needed
add idempotence test
add imagenet no split insertion test
fix split layer insertion bug with in-place layers
remove unnecessary include
eliminate some cruft by relying on std::map default initializations
get rid of messy snprintf string concatenation
get_split_blob_name returns a string to remove some verbosity
remove redundant add_bottom (immediately cleared and then re-added)
add test for layer with two tops that are inputs to multiple layers
fix comment typo
remove pointlessly duplicated CheckGradientExhaustive calls (I screwed up when merging, I think)
change \" in test_split_layer to ' for readability
allow in place computation of SplitLayer 0th top blob
give first top split blob same name as bottom blob
change \n's to less distracting spaces in hard-coded proto strings
eliminate redundant code with get_split_blob_name method
some cleanup
add split layer insertion tests; move split insertion code to util file
add split layer tests
add split layer tests
make split_layer backward obey propagate_down
Merge pull request #116 from aravindhm/tanh
Added a test for the tanh layer.
Added tanh activation function layer.
Merge pull request #142 from shelhamer/data-aux
bring imagenet docs back to reality
bring mnist docs back to reality
fix + rename lenet training script
harmonize imagenet example, name caffe reference model CaffeNet
fix mnist, add deploy net example
TODO cifar example
everything in its right place
include model checksum, you never know these days
fetch caffe_reference_imagenet_model
swap ilsvrc data with fetch script
explain ignore, and ignore data, models, and examples
file models
fix mnist comments in cifar example
Make tools/ for core binaries, stow scripts/ in tools/extra
file mnist
add imagenet mean file
move imagenet splits + synsets to data
Merge pull request #164 from t-abe/fix-typo
Fix error message typo in SoftmaxWithLossLayer
Merge pull request #154 from sguada/leveldb_max_open_files
Set leveldb options.max_open_files = 100. Fix #13 and #38
minor README fix
More comments in Makefile.config.example
more instructions on how to contribute
Merge pull request #157 from sergeyk/master
Updated README with doc info
Safer docs/ build process: into own folder
improved docs-building script
Moving gh-pages docs to docs/ folder, with script to build them
Properly index windows in detector list mode
fix detector's coordinate mapping for images smaller than IMAGE_DIM
Merge pull request #123 from longjon/master
Revert "Merge pull request #114 from jeffdonahue/dags-by-split"
don't pass LDFLAGS when only performing compilation (-c)
add contributing guide
Merge pull request #114 from jeffdonahue/dags-by-split
Enforce that new_height and new_width are both 0 or both > 0
Fixed typos to pass test_images_layer
Renamed input_layer to images_layer
Added the option to resize_image to resize images using cv::resize while reading them
Fixed input_layer to pass tests, added cat image to data to perform the tests
Added input_layer to set of layers and to factory
Draft for Input_layer copied from Data_layer
remove unnecessary include
eliminate some cruft by relying on std::map default initializations
get rid of messy snprintf string concatenation
get_split_blob_name returns a string to remove some verbosity
remove redundant add_bottom (immediately cleared and then re-added)
add test for layer with two tops that are inputs to multiple layers
fix comment typo
remove pointlessly duplicated CheckGradientExhaustive calls (I screwed up when merging, I think)
change \" in test_split_layer to ' for readability
allow in place computation of SplitLayer 0th top blob
give first top split blob same name as bottom blob
change \n's to less distracting spaces in hard-coded proto strings
eliminate redundant code with get_split_blob_name method
some cleanup
add split layer insertion tests; move split insertion code to util file
add split layer tests
add split layer tests
make split_layer backward obey propagate_down
add SplitLayer and Net::AddSplits to transform shared bottom blobs into split layers
define by := (no need for re-expansion)
python requirements: don't fear the future
add shebang to python scripts
add macro for numpy < 1.7
Merge pull request #106 from tdomhan/sigmoidlayer
fixed copyright
sigmoid layer cpu and gpu code
added sigmoid layer
Merge pull request #104 from sergeyk/master
selective_search_demo final updated version
detector.py refactored with argparse (was gflags)
Updated detection demo notebook. - Works with new detector.py - Everything is run automatically from cells.
git-ignoring ipython notebook checkpoints
moving selective_search_demo notebook to examples/
Update LICENSE
Merge pull request #103 from Yangqing/master
bugfix regarding #100
Update net.cpp
Merge pull request #98 from kloudkl/check_data_size
Set data_size_initialized to true after data_size is initialized
add CXXFLAGS for libstdc++ on OS X 10.9
Merge pull request #94 from kloudkl/image_data_size
Add script to resize and crop images in parallel using mincepie
Check data size when converting images into leveldb
include pip requirements.txt for python deps
Merge pull request #91 from kloudkl/plot_training_log
Remove trailing whitespace in example gnuplot script
Add python matplotlib example to plot the training log
Add gnuplot example to plot the training log
Update script to parse log format that contains test iteration
Print iteration along with every test score in Solver::Test
Extract elapsed seconds since the start of solving from training log
Extract learning rate from training log
replace bundled install instructions with link to site
Merge pull request #90 from sguada/parselog
Use sed instead of awk to find the Iteration
Update parselog.sh
Extract Iteration from log instead of computing it from parameters
Merge pull request #89 from sguada/parselog
Added bash script to parse log and extract training loss, and test loss and accuracy
Merge pull request #83 from sguada/net_speed
More detailed net_speed_benchmark
fix path problem in train_mnist.sh
Merge pull request #70 from petewarden/buffer-overflow
Merge pull request #72 from sguada/solver_device_id
Rename devicequery.cpp to device_query.cpp
Fix for buffer overflow problem with long filenames when setting up the LevelDB
Merge pull request #69 from sguada/solver_device_id
Update solver.cpp
Update caffe.proto
Update devicequery.cpp
Added device_query.cpp to examples/ to get basic information about the current GPU device or other device_id
Added device_id to solver.prototxt and to solver.cpp
fix flatten layer backwards to dummy return
removing Makefile.config
os x installation instructions
Makefile.config removed in favor of .example file with more verbose explanations of paths.
remove linking against mkl_intel_thread: unneeded and gives hard-to-debug errors on os x
Merge pull request #62 from viirya/master
Fix test_data_layer segfault by adding destructor to join pthread
note pretrained model licensing: academic / non-commercial use only
read single input, load/save csv, and record windows
remove outdated reference to input size, debugging print
choose proper thread number per block according to CUDA architecture.
fix program path.
align detector comments to reality
Merge pull request #61 from kloudkl/master
Save the last batch of data in image set conversion
detect by window list
replace magic numbers with variable names in comments
fix ImageNet solver max iteration typo
automagically set detection batch size from network
document power_wrapper -> detector in detection notebook
Merge pull request #56 from shelhamer/detection-wrapper
promote power_wrapper to 'detection' submodule
groom power_wrapper flags (cont'd)
note power_wrapper TODOs
generalize power_wrapper to different networks and inputs
groom power_wrapper flags
python lint
ignore distribute dir
give batch size efficiency advice
default power_wrapper batch size to 10 (aeca741a69 cont'd)
Merge pull request #51 from sguada/solver_test
Do snapshot after computing loss and test accuracy
include install notes
include intro, license, and citing in README
License under BSD
Merge pull request #11 from longjon/master
cleanup whitespace
Merge pull request #29 from kloudkl/master
Merge pull request #34 from forresti/master
setting default power_wrapper batch size to match the imagenet_deploy prototxt
Expose params in Python interface
Add Python interface to layer blobs
Add removing distribute directory when make clean
Add make proto target to seperately generate caffe/proto/caffe.pb.h
Seperated build, distribute and source directories
Merge pull request #18 from jeffdonahue/bvlc
change imagenet_val batch size from 200 to intended 50
point caffe url to bvlc
bringing license up to date with gh-pages version
updated detection demo notebook with picture of two cats
Merge pull request #10 from sergeyk/selective_search_proposals2
minor edit
selective search notebook and renaming to power_wrapper
fixed bug that renormalized window crops on second resize
center_only and corners modes work correctly
processing images in batch, with option to use selective search window proposals
renaming"
Update README.md
Merge pull request #9 from jeffdonahue/fixflattenbug
fix really stupid bug in flatten layer (and add test that shows the failure case; not sure why CheckGradientExhaustive didn't catch it)
lenet.prototxt loss layer rename
mnist train script
Several changes:
get_mnist.sh: changed the script to generate leveldb as well.
convert script: spacing
Merge pull request #7 from jeffdonahue/headers
modify makefile to recompile on changes to header files
Update README.md
Merge pull request #6 from jeffdonahue/flatten
add flatten layer
net.cpp: LOG to DLOG
io.cpp: changed back CV_LOAD_IMAGE_COLOR for earlier versions of opencv
Update io.cpp
git ignore
net speed benchmark: set device 0
removed the -Wl flag which was an earlier experimental try
makefile update
Merge branch 'master' of github.com:Yangqing/caffe
makefile: add both lib and lib64 to the cuda library path.
makefile: added a MATLAB_DIR variable. pycaffe and matcaffe will not be compiled in default unless one calls make pycaffe or make matcaffe explicitly.
update Makefile and add some more docs
Merge remote-tracking branch 'origin/master'
cleanup and include ILSVRC mean image
first pass at matlab wrapper (somewhat messy still)
fix Makefile problem
fixed minor typo in imagenet wrapper
cleaned makefile a little bit
Merge branch 'master' of github.com:Yangqing/caffe
remove remaining distributed solver stuff
remove caffe header for distributed solver
removed the unsuccessful distributed solver code
fix pycaffe dependency
fixed the missing CV flag
makefile: not compile test in default
Merge branch 'master' of github.com:Yangqing/caffe
makefile: fixed the nvcc path
io.cpp: changed the imread flag to cv::IMREAD_COLOR
Merge branch 'master' of github.com:Yangqing/caffe
added explanation notes to syncedmem
imagenet_solver.prototxt: added back the missing test line, not sure when it slipped off the repo
Merge branch 'master' of github.com:Yangqing/caffe
imagenet deploy prototxt: instead of having a data layer, this network proto takes an external blob called data. The shape is hardcoded to accompany the imagenet python wrapper at python/caffe/imagenet/wrapper.py. You need to change the shape if you intend to use other shapes.
print status message on error opening leveldb
Merge branch 'master', remote-tracking branch 'origin'
removed the StillFresh function that was used to make sure training does not happen with an earlier version of code.
Made a major change: when initializing a network, the input size are no longer provided by an additional vector of blobs, but should be specified in the netparameters proto by the field "input_dim". This avoid the often awkward code of creating a dummy input vector just for the sake of initializing the network.
wrapper update
finetune code
pycaffe: added a temporary numpy 1.6 compile solution
misc update
pycaffe update and imagenet wrapper
pycaffe update
linecount improvement
ilsvrc 2012 mean
removed obsolete scripts
python reorganization
changed makefile, and removed the no longer needed cuda convnet translator.
changed the python file paths
added pycaffe wrapper. Preparing to clean the structure
Merge branch 'master' of github.com:Yangqing/caffe
remove python deps
stochastic pooling: avoid nan
io.hpp bugfix
added infogain loss layer
bugfix
misc update
Merge branch 'master' of github.com:Yangqing/caffeine
ilsvrc 2012 train file list
distributed solver still having bugs. Pausing for now...
distributed solver: small fix, still bugs
distributed server update. bug in synchronous connections.
data layer: random skip
working asynchronous sgd code. may have errors.
distributed solver - not checked thoroughly
solver minor change
accuracy layer: also produce logprob
imagenet solver 2nd try
imagenet test prototxt
solver restructuring: now all prototxt are specified in the solver protocol buffer
stochastic pooling test
test convolution more thoroughly
script to convert cifar data
script to get cifar
test net scripts
data_layer: more clear logging
syncedmem: added code to not use cudamalloc/cudafree
data_layer: do center cropping when testing
common.cpp: rand seed fix
Merge branch 'master' of github.com:Yangqing/caffeine
pooling layer: added stochastic pooling layer, not tested, compilable
convert_imageset.cpp script: added error message
caffe common cpp: fixed an embarassing bug
removed an accidental mnist update
python code: use BGR order to match the C++ code
syncedmem bugfix
option to run on cpu without gpu
imagenet solver: a better decreasing policy
bugfix and made the C++ interface for creating leveldb
Merge branch 'master' of github.com:Yangqing/caffe
added back opencv dependency and convert scripts
added back opencv dependency and convert scripts
regarding https://plus.google.com/113952791760990667476/posts/Q5fwQY6JeEq - stopped the adagrad attempt.
neuron layer test: added bnll
bugfix
Merge branch 'master' of github.com:Yangqing/caffe
bnll
removed the old transcribe script.
pushing missing checkout
reverted the layer register effort. Live today, fight tomorrow.
Merge branch 'master' of github.com:Yangqing/caffe
simply inreasing report interval
Merge branch 'master' of github.com:Yangqing/caffeine
transcribe leveldb
put registration commands to cpp files
Merge branch 'master' of github.com:Yangqing/caffe
Register pattern for layers
icsi makefile for the record
common.cpp rand seed:  do time(NULL) so we can have different initializations
data layer race condition bugfix
Merge branch 'master' of github.com:Yangqing/caffe
solver stepsize: float -> int32
conv layer warning
prefetcher race condition
common: added DeviceQuery() function
conv_layer bugfix
script t- write leveldb
train_net update
net update
cosmetics
imagenet scripts and synset files
need backward computation, and train_net resume point. Not debugged.
allow setting custom weight decay
data layer log
imagenet prototxt: init bias 0.1
unchecked: using mean file.
compute image mean code
freshness
cleaning codes
mnist demo
add mnist data
mnist updates
Reorganization of codes.
removed the net proto test that relies on external data
Merge branch 'master' of github.com:Yangqing/caffeine
solver: added snapshotting ability
indentation
Moved the layer factory implementation to cpp; added snapshot and restore functions to solver.
Merge branch 'master' of github.com:Yangqing/caffe
draw a network proto
pyutil update
allow in-place neuron layers
common.hpp linting
Merge branch 'master' of github.com:Yangqing/caffe
embarassing update
license
added custom learning rate for individual blobs
caffe relu layer update, not sure if it's useful or not
pooling layer: max pooling: removed the max threshold
require sm_2x and above
snapshot. prepare to debug
removed opencv dependency for easier distribution
data layer pthread function fix
makefile cleaning: now it supports -j while the old version has bugs in dependencies
misc update
blob math preparation
cpplint
dropout serious bugfix. Seems to be working...
relu gradient: >=0 -> >0
cleaning some logging print
layer initialization
misc update
misc update. Moved the data to caffe/src/ and will not store it in the repo any more. changed the pooling behavior so now ave pooling runs according to the pooling region size.
softmaxwithloss layer: softmax + loss
misc update
working on translator
misc update
common.hpp/cpp update, and lenet using random subcrop
misc update
add tcmalloc
caffe test convolution
misc sample programs
data layer: using pthread
bugfix
scripts to convert dataset
datalayer random cropping, not tested
misc update
misc update...
lenet training code
mnist network generation
solver
euclidean layer update
mnist leveldb data generation
layer more debug msg
data layer: allow scaling and subtraction
convert scripts
data conversion
simple forward test
a bunch of updates.
test loading from text file
blob cpp bugfix
updated a bunch of things, ready to test if it breaks things
started writing solver
 blob
more restrictions.
more cpplint
cpplint
make caffe.hpp the only header one need
io
xavier filler
inner product bugfix
forgot to add the renamed file
inner product bugfix: not tested yet
softmax bug fix and net testing
net
a lot of modifications - disallow copy constructors and misc
multinomial logistic loss
softmax test
bugfix
Merge branch 'master' of github.com:Yangqing/caffe
caffe proto txt
softmax layer, test to be written
test code log
net cpp working version
data layer modification, and net header
pyutil
python init
cpplint
renaming
data layer testing
a few updates
proto update
more cpplint
more cpplint
pylint and code cleaning
copyright message
the previous submit did not include the layer factory (blush)
layer_factory, and misc update
pooling layer
pooling layer cpu
Update README.md
naming. I might regret it someday.
minor updates
lrn backward
lrn layer gpu forward
fixed bug
convolution layer. I might have broken something in im2col.
layer implementation now purely in layer.hpp
code cleaning
im2col works
wording
im2col: using cpu for now.
non-working version
im2col backward gpu
im2col
makefile
bugfix for lrn
makefile bugfix
changed the test structure
minor update
exhaustive test mode
gradient
renaming
lrn forward
fix
misc update
misc update
fix test: skip if gpu version too low
padding layer cuda code, need debug
inner product
inner product forward backward
update
update
bugfix
Merge branch 'master' of github.com:Yangqing/caffeine
gemm util
updates
naming
working version
comment out debug log
figured out the bug - it's curand
embarassing bugfix
misc update
working gradient check
misc update
gradient check test
misc update
misc update
misc udpate
misc update
misc update
working update
working update
working halfway into dropout, machine down, changing machine
test update
exclude precompiled protobuffer
makefile
Makefile
makefile
misc update
misc update
misc update
misc update
misc add
some updates
common.hpp update
misc update
failing test, needs to be checked.
man I am changing ideas so fast.
organization
misc test updates
makefile order fix, more test.
run test when make test.
converted to glog
compilable now.
common bugfix
a bunch of updates. to be checked on durian. does not build.
first try
Initial commit
